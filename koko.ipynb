{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /mnt/data1/backup/viswaz/Project_K/.venv/bin/pip: /mnt/data1/backup/viswaz/Project_k/Project_K/.venv/bin/python: bad interpreter: No such file or directory\n",
      "/bin/bash: /mnt/data1/backup/viswaz/Project_K/.venv/bin/pip: /mnt/data1/backup/viswaz/Project_k/Project_K/.venv/bin/python: bad interpreter: No such file or directory\n",
      "/bin/bash: /mnt/data1/backup/viswaz/Project_K/.venv/bin/pip: /mnt/data1/backup/viswaz/Project_k/Project_K/.venv/bin/python: bad interpreter: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers bitsandbytes accelerate datasets peft trl\n",
    "!pip install transformers trl accelerate torch bitsandbytes peft datasets -qU\n",
    "!pip install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
=======
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 4.40.2\n",
      "Uninstalling transformers-4.40.2:\n",
      "  Would remove:\n",
      "    /mnt/data1/backup/viswaz/Project_K/.venv/bin/transformers-cli\n",
      "    /mnt/data1/backup/viswaz/Project_K/.venv/lib/python3.10/site-packages/transformers-4.40.2.dist-info/*\n",
      "    /mnt/data1/backup/viswaz/Project_K/.venv/lib/python3.10/site-packages/transformers/*\n",
      "Proceed (Y/n)? ^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0mFound existing installation: transformers 4.40.2\n",
      "Uninstalling transformers-4.40.2:\n",
      "  Would remove:\n",
      "    /mnt/data1/backup/viswaz/Project_K/.venv/bin/transformers-cli\n",
      "    /mnt/data1/backup/viswaz/Project_K/.venv/lib/python3.10/site-packages/transformers-4.40.2.dist-info/*\n",
      "    /mnt/data1/backup/viswaz/Project_K/.venv/lib/python3.10/site-packages/transformers/*\n",
      "Proceed (Y/n)? "
     ]
    }
   ],
   "source": [
    "!pip uninstall transformers bitsandbytes accelerate datasets peft trl\n",
    "!pip uninstall transformers trl accelerate torch bitsandbytes peft datasets\n",
    "!pip uninstall flash-attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
>>>>>>> f2bc1641 (done)
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the instruct_tune_dataset dataset\u001b[39;00m\n\u001b[1;32m      4\u001b[0m dataset \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDobby091/koko\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the instruct_tune_dataset dataset\n",
    "dataset = load_dataset(\"Dobby091/koko\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pdf_filename': '228_6.pdf', 'question': 'What is the reproducibility range for chromium content at 1 to 5 percent?', 'answer': 'Reproducibility is Â±0.120 percent.'}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"test\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples: 15\n",
      "Number of test samples: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['pdf_filename', 'question', 'answer'],\n",
       "        num_rows: 15\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['pdf_filename', 'question', 'answer'],\n",
       "        num_rows: 2\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Select the first 1000 samples in the train set and the first 200 samples in the test set\n",
    "train_dataset = dataset['train'].select(range(15))\n",
    "test_dataset = dataset['test'].select(range(2))\n",
    "\n",
    "# Create a new `DatasetDict` to store the selected samples\n",
    "selected_dataset_dict = DatasetDict({'train': train_dataset, 'test': test_dataset})\n",
    "\n",
    "# Print the number of samples in each split\n",
    "print(f\"Number of train samples: {len(train_dataset)}\")\n",
    "print(f\"Number of test samples: {len(test_dataset)}\")\n",
    "\n",
    "selected_dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in /usr/local/lib/python3.10/dist-packages (0.10.36)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.35 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.10.36)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.5)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.3)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.9)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse<0.2.0,>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.4)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.9.48)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.13 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.18)\n",
      "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.12)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.6)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.3.0,>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.2.4)\n",
      "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.6)\n",
      "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.22)\n",
      "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-agent-openai<0.3.0,>=0.1.4->llama-index) (1.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /root/.local/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index) (1.6.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index) (1.16.0)\n",
      "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index) (0.27.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index) (2024.3.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index) (8.3.0)\n",
      "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index) (0.6.6)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index) (2.0.30)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index) (1.2.14)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /usr/lib/python3/dist-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index) (9.0.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index) (2.2.2)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index) (0.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index) (4.66.4)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index) (1.0.8)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index) (0.1.19)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /root/.local/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index) (4.11.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index) (1.26.4)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index) (3.3)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index) (3.8.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index) (3.9.5)\n",
      "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index) (2.31.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index) (0.9.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index) (6.0.1)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.2.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (0.0.26)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n",
      "Requirement already satisfied: llama-parse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index) (0.4.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.35->llama-index) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.35->llama-index) (1.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.35->llama-index) (1.9.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.35->llama-index) (6.0.5)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.35->llama-index) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.35->llama-index) (23.2.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\n",
      "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.35->llama-index) (2.7.1)\n",
      "Requirement already satisfied: idna in /usr/lib/python3/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.35->llama-index) (3.3)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.35->llama-index) (1.3.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.35->llama-index) (4.3.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.35->llama-index) (1.0.5)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.35->llama-index) (2020.6.20)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.35->llama-index) (0.14.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.35->llama-index) (2024.5.10)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.35->llama-index) (8.0.3)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.35->llama-index) (1.4.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index) (1.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.35->llama-index) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.35->llama-index) (1.26.5)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.35->llama-index) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.35->llama-index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.35->llama-index) (3.21.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/.local/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.35->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.35->llama-index) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.35->llama-index) (2024.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /root/.local/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.35->llama-index) (1.2.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /root/.local/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.35->llama-index) (24.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.35->llama-index) (2.18.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.35->llama-index) (0.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.35->llama-index) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-embeddings-huggingface in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
      "Requirement already satisfied: huggingface-hub[inference]>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-huggingface) (0.23.0)\n",
      "Requirement already satisfied: sentence-transformers<3.0.0,>=2.6.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-huggingface) (2.7.0)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-huggingface) (0.10.36)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.66.4)\n",
      "Requirement already satisfied: packaging>=20.9 in /root/.local/lib/python3.10/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (24.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.31.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/.local/lib/python3.10/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.11.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2024.3.1)\n",
      "Requirement already satisfied: minijinja>=1.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.0.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.9.5)\n",
      "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.28.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.8.1)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.6.0)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.2.14)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.2.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (8.3.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.16.0)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.0.30)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.1.19)\n",
      "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /root/.local/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.3)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.9.0)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.0.8)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /usr/lib/python3/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (9.0.1)\n",
      "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.6.6)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.26.4)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (4.40.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (1.13.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (1.4.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (2.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.9.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.5)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.4.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.0.3)\n",
      "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.7.1)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2020.6.20)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.0.5)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.3.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (4.3.0)\n",
      "Requirement already satisfied: idna in /usr/lib/python3/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.3)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.14.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2024.5.10)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (8.0.3)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.26.5)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.0.3)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (12.1.105)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (11.4.5.107)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (1.12)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (2.20.5)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (8.9.2.26)\n",
      "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (2.3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (12.4.127)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (0.4.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.21.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/.local/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2024.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (3.5.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /root/.local/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.18.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install llama-index\n",
    "# !pip install llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings, SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM is explicitly disabled. Using MockLLM.\n"
     ]
    }
   ],
   "source": [
    "# import any embedding model on HF hub (https://huggingface.co/spaces/mteb/leaderboard)\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "# Settings.embed_model = HuggingFaceEmbedding(model_name=\"thenlper/gte-large\") # alternative model\n",
    "\n",
    "Settings.llm = None\n",
    "Settings.chunk_size = 256\n",
    "Settings.chunk_overlap = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# articles available here:  {add GitHub repo}\n",
    "documents = SimpleDirectoryReader(\"pdf\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "# some ad hoc document refinement\n",
    "print(len(documents))\n",
    "for doc in documents:\n",
    "    if \"Member-only story\" in doc.text:\n",
    "        documents.remove(doc)\n",
    "        continue\n",
    "\n",
    "    if \"The Data Entrepreneurs\" in doc.text:\n",
    "        documents.remove(doc)\n",
    "\n",
    "    if \" min read\" in doc.text:\n",
    "        documents.remove(doc)\n",
    "\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "IS : â228 ( Part 4 ) - 1987 \n",
      "Indian Standard \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 4 DETERYlNATlON OF TOTAL CARBON \n",
      "BY GARVIMETRIC METHOD \n",
      "(FOR CARBON > O-1 PERCENT ) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 4 ) (Third R cvision ) was adopted I)y \n",
      "the Indian Standards Institution on 16 January 1987, afirr the draft \n",
      "finalized by the Methods of Chemical Analysis of Pcrrous Metals \n",
      "Sectional Committre had been approved by the Structural and Mct;~ls \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemical analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "IS t \n",
      "Indian Standard 228 ( Part 5 ) - 1987 \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 6 DETERMINATION OF NICKEL BY \n",
      "DIMETHYLGLYOXIME ( GRAVIMETRIC ) METHOD \n",
      "( FOR NICKEL > 0â1 PERCENT) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 5 ) ( Third Revision ) was adopted by \n",
      "the Indian Standards Institution on 16 January 1987, after the draft \n",
      "finalized by the Methods of Chemical Analysis of Ferrous Metals \n",
      "Sectional Committee had been approved by the Strtictural and Metals \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemial analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "Accordingly, revision of IS : 228 was \n",
      "taken-up again and new series on methods of chemical analysis of \n",
      "steels including high alloy steels was published in various parts as \n",
      "IS : 228 ( Parts 1 to 13 ) ( see Appendix A ) covering separate method \n",
      "of analysis for each constituent in steels. However, IS : 228-1959* \n",
      "version has been retained for the analysis of pig iron and cast iron \n",
      "till a separate standard for analysis of pig iron and cast iron is \n",
      "published. \n",
      "0.2.1 This revision of IS : 228 (Part 6 )-1974t has been undertaken \n",
      "on the basis of experience gained during the implementation of the \n",
      "standard by the manufacturers and testing laboratories. \n",
      "0.3 In this revision, major modifications are: \n",
      "a) scope of the method has been modified by lowering the limit \n",
      "for determination of chromium from 0â5 to 0â1 percent; \n",
      "-.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# store docs into vector DB\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "# set number of docs to retreive\n",
    "top_k = 3\n",
    "\n",
    "# configure retriever\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=top_k,\n",
    ")\n",
    "# assemble query engine\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.5)],\n",
    ")\n",
    "# query documents\n",
    "query = \"When was this standard adopted?\"\n",
    "response = query_engine.query(query)\n",
    "\n",
    "# reformat response\n",
    "context = \"Context:\\n\"\n",
    "for i in range(top_k):\n",
    "    context = context + response.source_nodes[i].text + \"\\n\\n\"\n",
    "\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['pdf_filename', 'question', 'answer'],\n",
       "        num_rows: 15\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['pdf_filename', 'question', 'answer'],\n",
       "        num_rows: 2\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "<s>[INST]###Instruction:\n",
      "below context is from 228_4.pdf, answer the following questions based on the context given \n",
      "\n",
      "\n",
      "###pdf_filename:\n",
      "228_4.pdf\n",
      "\n",
      "###context:\n",
      "Context:\n",
      "IS : â228 ( Part 4 ) - 1987 \n",
      "Indian Standard \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 4 DETERYlNATlON OF TOTAL CARBON \n",
      "BY GARVIMETRIC METHOD \n",
      "(FOR CARBON > O-1 PERCENT ) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 4 ) (Third R cvision ) was adopted I)y \n",
      "the Indian Standards Institution on 16 January 1987, afirr the draft \n",
      "finalized by the Methods of Chemical Analysis of Pcrrous Metals \n",
      "Sectional Committre had been approved by the Structural and Mct;~ls \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemical analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "IS t \n",
      "Indian Standard 228 ( Part 5 ) - 1987 \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 6 DETERMINATION OF NICKEL BY \n",
      "DIMETHYLGLYOXIME ( GRAVIMETRIC ) METHOD \n",
      "( FOR NICKEL > 0â1 PERCENT) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 5 ) ( Third Revision ) was adopted by \n",
      "the Indian Standards Institution on 16 January 1987, after the draft \n",
      "finalized by the Methods of Chemical Analysis of Ferrous Metals \n",
      "Sectional Committee had been approved by the Strtictural and Metals \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemial analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "Accordingly, revision of IS : 228 was \n",
      "taken-up again and new series on methods of chemical analysis of \n",
      "steels including high alloy steels was published in various parts as \n",
      "IS : 228 ( Parts 1 to 13 ) ( see Appendix A ) covering separate method \n",
      "of analysis for each constituent in steels. However, IS : 228-1959* \n",
      "version has been retained for the analysis of pig iron and cast iron \n",
      "till a separate standard for analysis of pig iron and cast iron is \n",
      "published. \n",
      "0.2.1 This revision of IS : 228 (Part 6 )-1974t has been undertaken \n",
      "on the basis of experience gained during the implementation of the \n",
      "standard by the manufacturers and testing laboratories. \n",
      "0.3 In this revision, major modifications are: \n",
      "a) scope of the method has been modified by lowering the limit \n",
      "for determination of chromium from 0â5 to 0â1 percent; \n",
      "-.\n",
      "\n",
      "\n",
      "\n",
      "###question:\n",
      "2. When was this standard adopted?[/INST]\n",
      "\n",
      "###answer:\n",
      "1987-01-16 00:00:00</s>\n",
      "---------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<s>[INST]###Instruction:\\nbelow context is from 228_4.pdf, answer the following questions based on the context given \\n\\n\\n###pdf_filename:\\n228_4.pdf\\n\\n###context:\\nContext:\\nIS : â228 ( Part 4 ) - 1987 \\nIndian Standard \\nMETHODS FOR \\nCHEMICAL ANALYSIS OF STEELS \\nPART 4 DETERYlNATlON OF TOTAL CARBON \\nBY GARVIMETRIC METHOD \\n(FOR CARBON > O-1 PERCENT ) \\n( Third Revision ) \\n0. FOREWORD \\n0.1 This Indian Standard ( Part 4 ) (Third R cvision ) was adopted I)y \\nthe Indian Standards Institution on 16 January 1987, afirr the draft \\nfinalized by the Methods of Chemical Analysis of Pcrrous Metals \\nSectional Committre had been approved by the Structural and Mct;~ls \\nDivision Council. \\n0.2 IS : 228, which was issued as a tentative standard in 1952 and \\nrevised in 1959, covered the chemical analysis of pig iron, cast iron and \\nplain carbon and low alloy steels.\\n\\nIS t \\nIndian Standard 228 ( Part 5 ) - 1987 \\nMETHODS FOR \\nCHEMICAL ANALYSIS OF STEELS \\nPART 6 DETERMINATION OF NICKEL BY \\nDIMETHYLGLYOXIME ( GRAVIMETRIC ) METHOD \\n( FOR NICKEL > 0â1 PERCENT) \\n( Third Revision ) \\n0. FOREWORD \\n0.1 This Indian Standard ( Part 5 ) ( Third Revision ) was adopted by \\nthe Indian Standards Institution on 16 January 1987, after the draft \\nfinalized by the Methods of Chemical Analysis of Ferrous Metals \\nSectional Committee had been approved by the Strtictural and Metals \\nDivision Council. \\n0.2 IS : 228, which was issued as a tentative standard in 1952 and \\nrevised in 1959, covered the chemial analysis of pig iron, cast iron and \\nplain carbon and low alloy steels.\\n\\nAccordingly, revision of IS : 228 was \\ntaken-up again and new series on methods of chemical analysis of \\nsteels including high alloy steels was published in various parts as \\nIS : 228 ( Parts 1 to 13 ) ( see Appendix A ) covering separate method \\nof analysis for each constituent in steels. However, IS : 228-1959* \\nversion has been retained for the analysis of pig iron and cast iron \\ntill a separate standard for analysis of pig iron and cast iron is \\npublished. \\n0.2.1 This revision of IS : 228 (Part 6 )-1974t has been undertaken \\non the basis of experience gained during the implementation of the \\nstandard by the manufacturers and testing laboratories. \\n0.3 In this revision, major modifications are: \\na) scope of the method has been modified by lowering the limit \\nfor determination of chromium from 0â5 to 0â1 percent; \\n-.\\n\\n\\n\\n###question:\\n2. When was this standard adopted?[/INST]\\n\\n###answer:\\n1987-01-16 00:00:00</s>'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_prompt(sample):\n",
    "    bos_token = \"<s>\"\n",
    "    base_prompt1 = \"below context is from \"\n",
    "    base_prompt2 = \", answer the following questions based on the context given \\n\"\n",
    "    document = sample['pdf_filename']\n",
    "    # context = sample['context']\n",
    "    answer = sample['answer']\n",
    "    question = sample['question']\n",
    "    eos_token = \"</s>\"\n",
    "    full_prompt = \"\"\n",
    "    full_prompt += bos_token\n",
    "    full_prompt += \"[INST]\"\n",
    "    full_prompt += \"###Instruction:\\n\"\n",
    "    full_prompt += base_prompt1\n",
    "    full_prompt += document\n",
    "    full_prompt += base_prompt2\n",
    "    # full_prompt += \"[INST]\"\n",
    "    full_prompt += \"\\n\\n###pdf_filename:\\n\" + document\n",
    "    full_prompt += \"\\n\\n###context:\\n\" + context\n",
    "    full_prompt += \"\\n\\n###question:\\n\" + question\n",
    "    full_prompt += \"[/INST]\"\n",
    "    full_prompt += \"\\n\\n###answer:\\n\" + answer\n",
    "    full_prompt += eos_token\n",
    "    print(\"------------------\")\n",
    "    print(full_prompt)\n",
    "    print(\"---------------------------------------------------------------------------------------------------------------\")\n",
    "    return full_prompt\n",
    "\n",
    "create_prompt(selected_dataset_dict[\"train\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "# model_id=\"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "model_id=\"mistralai/Mixtral-8x7B-v0.1\"\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards:   0%|          | 0/19 [02:44<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[138], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHF_TOKEN\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhf_LOvfCARVWcwegIKBEjegOVbJzzytNgTUCz\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnf4_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:563\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    562\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:3436\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3433\u001b[0m \u001b[38;5;66;03m# We'll need to download and cache each checkpoint shard if the checkpoint is sharded.\u001b[39;00m\n\u001b[1;32m   3434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sharded:\n\u001b[1;32m   3435\u001b[0m     \u001b[38;5;66;03m# rsolved_archive_file becomes a list of files that point to the different checkpoint shards in this case.\u001b[39;00m\n\u001b[0;32m-> 3436\u001b[0m     resolved_archive_file, sharded_metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_checkpoint_shard_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3445\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3446\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3447\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3448\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3449\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3452\u001b[0m     is_safetensors_available()\n\u001b[1;32m   3453\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resolved_archive_file, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m   3454\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m resolved_archive_file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.safetensors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3455\u001b[0m ):\n\u001b[1;32m   3456\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m safe_open(resolved_archive_file, framework\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:1038\u001b[0m, in \u001b[0;36mget_checkpoint_shard_files\u001b[0;34m(pretrained_model_name_or_path, index_filename, cache_dir, force_download, proxies, resume_download, local_files_only, token, user_agent, revision, subfolder, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m shard_filename \u001b[38;5;129;01min\u001b[39;00m tqdm(shard_filenames, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading shards\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m show_progress_bar):\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1037\u001b[0m         \u001b[38;5;66;03m# Load from URL\u001b[39;00m\n\u001b[0;32m-> 1038\u001b[0m         cached_filename \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[43m            \u001b[49m\u001b[43mshard_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_commit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;66;03m# We have already dealt with RepositoryNotFoundError and RevisionNotFoundError when getting the index, so\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;66;03m# we don't have to catch them here.\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:398\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 398\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    413\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m _get_cache_file_to_return(path_or_repo_id, full_filename, cache_dir, revision)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1221\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, legacy_cache_layout, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[1;32m   1203\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m   1204\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1218\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m   1219\u001b[0m     )\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m   1223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m   1225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m   1230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1232\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1234\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m   1235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1237\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1367\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, headers, proxies, etag_timeout, endpoint, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1365\u001b[0m Path(lock_path)\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1366\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[0;32m-> 1367\u001b[0m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.incomplete\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1370\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1376\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1377\u001b[0m     _create_symlink(blob_path, pointer_path, new_blob\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pointer_path\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1884\u001b[0m, in \u001b[0;36m_download_to_tmp_and_move\u001b[0;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download)\u001b[0m\n\u001b[1;32m   1881\u001b[0m         _check_disk_space(expected_size, incomplete_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[1;32m   1882\u001b[0m         _check_disk_space(expected_size, destination_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[0;32m-> 1884\u001b[0m     \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1891\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1893\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownload complete. Moving file to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1894\u001b[0m _chmod_and_move(incomplete_path, destination_path)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:539\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[0m\n\u001b[1;32m    537\u001b[0m new_resume_size \u001b[38;5;241m=\u001b[39m resume_size\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 539\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m r\u001b[38;5;241m.\u001b[39miter_content(chunk_size\u001b[38;5;241m=\u001b[39mDOWNLOAD_CHUNK_SIZE):\n\u001b[1;32m    540\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m chunk:  \u001b[38;5;66;03m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[1;32m    541\u001b[0m             progress\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(chunk))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/response.py:576\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp):\n\u001b[0;32m--> 576\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    578\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m    579\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/response.py:519\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    518\u001b[0m     cache_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    521\u001b[0m         amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data\n\u001b[1;32m    522\u001b[0m     ):  \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    529\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[1;32m    530\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:466\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 466\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1303\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1300\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1301\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1302\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1305\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1159\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1159\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1161\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"HF_TOKEN\"] = \"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\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=nf4_config,\n",
    "    use_cache=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_size = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt, model):\n",
    "  encoded_input = tokenizer(prompt,  return_tensors=\"pt\", add_special_tokens=True)\n",
    "  model_inputs = encoded_input.to('cuda')\n",
    "\n",
    "  generated_ids = model.generate(**model_inputs,\n",
    "                                 max_new_tokens=512,\n",
    "                                 do_sample=True,\n",
    "                                 pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "  decoded_output = tokenizer.batch_decode(generated_ids)\n",
    "\n",
    "  return decoded_output[0].replace(prompt, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "probability tensor contains either `inf`, `nan` or element < 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[135], line 72\u001b[0m\n\u001b[1;32m      1\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124m<s>###Instruction:\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124mbelow context is from 228_4.pdf, answer the following questions based on the context given \u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124m1987-01-16 00:00:00</s>\u001b[39m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 72\u001b[0m \u001b[43mgenerate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[134], line 5\u001b[0m, in \u001b[0;36mgenerate_response\u001b[0;34m(prompt, model)\u001b[0m\n\u001b[1;32m      2\u001b[0m encoded_input \u001b[38;5;241m=\u001b[39m tokenizer(prompt,  return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m encoded_input\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m generated_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m decoded_output \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(generated_ids)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m decoded_output[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(prompt, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1622\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1614\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1615\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1616\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1617\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1618\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1619\u001b[0m     )\n\u001b[1;32m   1621\u001b[0m     \u001b[38;5;66;03m# 13. run sample\u001b[39;00m\n\u001b[0;32m-> 1622\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1623\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1629\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1631\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1633\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1634\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1636\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH:\n\u001b[1;32m   1637\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   1638\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   1639\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1640\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   1646\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:2829\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m \u001b[38;5;66;03m# sample\u001b[39;00m\n\u001b[1;32m   2828\u001b[0m probs \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(next_token_scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 2829\u001b[0m next_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   2831\u001b[0m \u001b[38;5;66;03m# finished sentences should have their next token be a padding token\u001b[39;00m\n\u001b[1;32m   2832\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eos_token_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: probability tensor contains either `inf`, `nan` or element < 0"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "<s>###Instruction:\n",
    "below context is from 228_4.pdf, answer the following questions based on the context given \n",
    "[INST]\n",
    "\n",
    "###pdf_filename:\n",
    "228_4.pdf\n",
    "\n",
    "###context:\n",
    "Context:\n",
    "IS : â228 ( Part 4 ) - 1987 \n",
    "Indian Standard \n",
    "METHODS FOR \n",
    "CHEMICAL ANALYSIS OF STEELS \n",
    "PART 4 DETERYlNATlON OF TOTAL CARBON \n",
    "BY GARVIMETRIC METHOD \n",
    "(FOR CARBON > O-1 PERCENT ) \n",
    "( Third Revision ) \n",
    "0. FOREWORD \n",
    "0.1 This Indian Standard ( Part 4 ) (Third R cvision ) was adopted I)y \n",
    "the Indian Standards Institution on 16 January 1987, afirr the draft \n",
    "finalized by the Methods of Chemical Analysis of Pcrrous Metals \n",
    "Sectional Committre had been approved by the Structural and Mct;~ls \n",
    "Division Council. \n",
    "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
    "revised in 1959, covered the chemical analysis of pig iron, cast iron and \n",
    "plain carbon and low alloy steels.\n",
    "\n",
    "IS t \n",
    "Indian Standard 228 ( Part 5 ) - 1987 \n",
    "METHODS FOR \n",
    "CHEMICAL ANALYSIS OF STEELS \n",
    "PART 6 DETERMINATION OF NICKEL BY \n",
    "DIMETHYLGLYOXIME ( GRAVIMETRIC ) METHOD \n",
    "( FOR NICKEL > 0â1 PERCENT) \n",
    "( Third Revision ) \n",
    "0. FOREWORD \n",
    "0.1 This Indian Standard ( Part 5 ) ( Third Revision ) was adopted by \n",
    "the Indian Standards Institution on 16 January 1987, after the draft \n",
    "finalized by the Methods of Chemical Analysis of Ferrous Metals \n",
    "Sectional Committee had been approved by the Strtictural and Metals \n",
    "Division Council. \n",
    "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
    "revised in 1959, covered the chemial analysis of pig iron, cast iron and \n",
    "plain carbon and low alloy steels.\n",
    "\n",
    "Accordingly, revision of IS : 228 was \n",
    "taken-up again and new series on methods of chemical analysis of \n",
    "steels including high alloy steels was published in various parts as \n",
    "IS : 228 ( Parts 1 to 13 ) ( see Appendix A ) covering separate method \n",
    "of analysis for each constituent in steels. However, IS : 228-1959* \n",
    "version has been retained for the analysis of pig iron and cast iron \n",
    "till a separate standard for analysis of pig iron and cast iron is \n",
    "published. \n",
    "0.2.1 This revision of IS : 228 (Part 6 )-1974t has been undertaken \n",
    "on the basis of experience gained during the implementation of the \n",
    "standard by the manufacturers and testing laboratories. \n",
    "0.3 In this revision, major modifications are: \n",
    "a) scope of the method has been modified by lowering the limit \n",
    "for determination of chromium from 0â5 to 0â1 percent; \n",
    "-.\n",
    "\n",
    "\n",
    "\n",
    "###question:\n",
    "2. When was this standard adopted?[/INST]\n",
    "\n",
    "###answer:\n",
    "1987-01-16 00:00:00</s>\n",
    "\"\"\"\n",
    "\n",
    "generate_response(prompt, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import AutoPeftModelForCausalLM, LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CASUAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "# args = TrainingArguments(\n",
    "#     output_dir = \"KOKO\",\n",
    "#     max_steps = 100,\n",
    "#     per_device_train_batch_size = 4,\n",
    "#     warmup_steps = 0.03,\n",
    "#     logging_steps = 10,\n",
    "#     save_strategy = \"epoch\",\n",
    "#     evaluation_strategy=\"steps\",\n",
    "#     eval_steps=20,\n",
    "#     learning_rate=2e-4,\n",
    "#     lr_scheduler_type='constant',\n",
    "# )\n",
    "\n",
    "gradient_accumulation_steps = 4  # adjust this value based on your GPU memory\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir = \"KOKO\",\n",
    "    max_steps = 100,\n",
    "    per_device_train_batch_size = 4,\n",
    "    gradient_accumulation_steps = gradient_accumulation_steps,  # add this line\n",
    "    warmup_steps = 0.03,\n",
    "    logging_steps = 10,\n",
    "    save_strategy = \"epoch\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=20,\n",
    "    learning_rate=2e-4,\n",
    "    lr_scheduler_type='constant',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 49 examples [00:00, 4542.50 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "<s>###Instruction:\n",
      "below context is from 228_4.pdf, answer the folwing questions based on the context given \n",
      "\n",
      "\n",
      "###context:\n",
      "Context:\n",
      "IS : â228 ( Part 4 ) - 1987 \n",
      "Indian Standard \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 4 DETERYlNATlON OF TOTAL CARBON \n",
      "BY GARVIMETRIC METHOD \n",
      "(FOR CARBON > O-1 PERCENT ) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 4 ) (Third R cvision ) was adopted I)y \n",
      "the Indian Standards Institution on 16 January 1987, afirr the draft \n",
      "finalized by the Methods of Chemical Analysis of Pcrrous Metals \n",
      "Sectional Committre had been approved by the Structural and Mct;~ls \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemical analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "IS t \n",
      "Indian Standard 228 ( Part 5 ) - 1987 \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 6 DETERMINATION OF NICKEL BY \n",
      "DIMETHYLGLYOXIME ( GRAVIMETRIC ) METHOD \n",
      "( FOR NICKEL > 0â1 PERCENT) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 5 ) ( Third Revision ) was adopted by \n",
      "the Indian Standards Institution on 16 January 1987, after the draft \n",
      "finalized by the Methods of Chemical Analysis of Ferrous Metals \n",
      "Sectional Committee had been approved by the Strtictural and Metals \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemial analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "Accordingly, revision of IS : 228 was \n",
      "taken-up again and new series on methods of chemical analysis of \n",
      "steels including high alloy steels was published in various parts as \n",
      "IS : 228 ( Parts 1 to 13 ) ( see Appendix A ) covering separate method \n",
      "of analysis for each constituent in steels. However, IS : 228-1959* \n",
      "version has been retained for the analysis of pig iron and cast iron \n",
      "till a separate standard for analysis of pig iron and cast iron is \n",
      "published. \n",
      "0.2.1 This revision of IS : 228 (Part 6 )-1974t has been undertaken \n",
      "on the basis of experience gained during the implementation of the \n",
      "standard by the manufacturers and testing laboratories. \n",
      "0.3 In this revision, major modifications are: \n",
      "a) scope of the method has been modified by lowering the limit \n",
      "for determination of chromium from 0â5 to 0â1 percent; \n",
      "-.\n",
      "\n",
      "\n",
      "\n",
      "###question:\n",
      "1. What standard does the text discuss?\n",
      "\n",
      "###answer:\n",
      "IS : 228 (Part 4) - 1987</s>\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "------------------\n",
      "<s>###Instruction:\n",
      "below context is from 228_4.pdf, answer the folwing questions based on the context given \n",
      "\n",
      "\n",
      "###context:\n",
      "Context:\n",
      "IS : â228 ( Part 4 ) - 1987 \n",
      "Indian Standard \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 4 DETERYlNATlON OF TOTAL CARBON \n",
      "BY GARVIMETRIC METHOD \n",
      "(FOR CARBON > O-1 PERCENT ) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 4 ) (Third R cvision ) was adopted I)y \n",
      "the Indian Standards Institution on 16 January 1987, afirr the draft \n",
      "finalized by the Methods of Chemical Analysis of Pcrrous Metals \n",
      "Sectional Committre had been approved by the Structural and Mct;~ls \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemical analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "IS t \n",
      "Indian Standard 228 ( Part 5 ) - 1987 \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 6 DETERMINATION OF NICKEL BY \n",
      "DIMETHYLGLYOXIME ( GRAVIMETRIC ) METHOD \n",
      "( FOR NICKEL > 0â1 PERCENT) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 5 ) ( Third Revision ) was adopted by \n",
      "the Indian Standards Institution on 16 January 1987, after the draft \n",
      "finalized by the Methods of Chemical Analysis of Ferrous Metals \n",
      "Sectional Committee had been approved by the Strtictural and Metals \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemial analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "Accordingly, revision of IS : 228 was \n",
      "taken-up again and new series on methods of chemical analysis of \n",
      "steels including high alloy steels was published in various parts as \n",
      "IS : 228 ( Parts 1 to 13 ) ( see Appendix A ) covering separate method \n",
      "of analysis for each constituent in steels. However, IS : 228-1959* \n",
      "version has been retained for the analysis of pig iron and cast iron \n",
      "till a separate standard for analysis of pig iron and cast iron is \n",
      "published. \n",
      "0.2.1 This revision of IS : 228 (Part 6 )-1974t has been undertaken \n",
      "on the basis of experience gained during the implementation of the \n",
      "standard by the manufacturers and testing laboratories. \n",
      "0.3 In this revision, major modifications are: \n",
      "a) scope of the method has been modified by lowering the limit \n",
      "for determination of chromium from 0â5 to 0â1 percent; \n",
      "-.\n",
      "\n",
      "\n",
      "\n",
      "###question:\n",
      "2. When was this standard adopted?\n",
      "\n",
      "###answer:\n",
      "1987-01-16 00:00:00</s>\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "------------------\n",
      "<s>###Instruction:\n",
      "below context is from 228_4.pdf, answer the folwing questions based on the context given \n",
      "\n",
      "\n",
      "###context:\n",
      "Context:\n",
      "IS : â228 ( Part 4 ) - 1987 \n",
      "Indian Standard \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 4 DETERYlNATlON OF TOTAL CARBON \n",
      "BY GARVIMETRIC METHOD \n",
      "(FOR CARBON > O-1 PERCENT ) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 4 ) (Third R cvision ) was adopted I)y \n",
      "the Indian Standards Institution on 16 January 1987, afirr the draft \n",
      "finalized by the Methods of Chemical Analysis of Pcrrous Metals \n",
      "Sectional Committre had been approved by the Structural and Mct;~ls \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemical analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "IS t \n",
      "Indian Standard 228 ( Part 5 ) - 1987 \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 6 DETERMINATION OF NICKEL BY \n",
      "DIMETHYLGLYOXIME ( GRAVIMETRIC ) METHOD \n",
      "( FOR NICKEL > 0â1 PERCENT) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 5 ) ( Third Revision ) was adopted by \n",
      "the Indian Standards Institution on 16 January 1987, after the draft \n",
      "finalized by the Methods of Chemical Analysis of Ferrous Metals \n",
      "Sectional Committee had been approved by the Strtictural and Metals \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemial analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "Accordingly, revision of IS : 228 was \n",
      "taken-up again and new series on methods of chemical analysis of \n",
      "steels including high alloy steels was published in various parts as \n",
      "IS : 228 ( Parts 1 to 13 ) ( see Appendix A ) covering separate method \n",
      "of analysis for each constituent in steels. However, IS : 228-1959* \n",
      "version has been retained for the analysis of pig iron and cast iron \n",
      "till a separate standard for analysis of pig iron and cast iron is \n",
      "published. \n",
      "0.2.1 This revision of IS : 228 (Part 6 )-1974t has been undertaken \n",
      "on the basis of experience gained during the implementation of the \n",
      "standard by the manufacturers and testing laboratories. \n",
      "0.3 In this revision, major modifications are: \n",
      "a) scope of the method has been modified by lowering the limit \n",
      "for determination of chromium from 0â5 to 0â1 percent; \n",
      "-.\n",
      "\n",
      "\n",
      "\n",
      "###question:\n",
      "3. What does the standard cover?\n",
      "\n",
      "###answer:\n",
      "Chemical analysis of pig iron, cast iron, plain carbon, and low alloy steels</s>\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "------------------\n",
      "<s>###Instruction:\n",
      "below context is from 228_4.pdf, answer the folwing questions based on the context given \n",
      "\n",
      "\n",
      "###context:\n",
      "Context:\n",
      "IS : â228 ( Part 4 ) - 1987 \n",
      "Indian Standard \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 4 DETERYlNATlON OF TOTAL CARBON \n",
      "BY GARVIMETRIC METHOD \n",
      "(FOR CARBON > O-1 PERCENT ) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 4 ) (Third R cvision ) was adopted I)y \n",
      "the Indian Standards Institution on 16 January 1987, afirr the draft \n",
      "finalized by the Methods of Chemical Analysis of Pcrrous Metals \n",
      "Sectional Committre had been approved by the Structural and Mct;~ls \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemical analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "IS t \n",
      "Indian Standard 228 ( Part 5 ) - 1987 \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 6 DETERMINATION OF NICKEL BY \n",
      "DIMETHYLGLYOXIME ( GRAVIMETRIC ) METHOD \n",
      "( FOR NICKEL > 0â1 PERCENT) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 5 ) ( Third Revision ) was adopted by \n",
      "the Indian Standards Institution on 16 January 1987, after the draft \n",
      "finalized by the Methods of Chemical Analysis of Ferrous Metals \n",
      "Sectional Committee had been approved by the Strtictural and Metals \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemial analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "Accordingly, revision of IS : 228 was \n",
      "taken-up again and new series on methods of chemical analysis of \n",
      "steels including high alloy steels was published in various parts as \n",
      "IS : 228 ( Parts 1 to 13 ) ( see Appendix A ) covering separate method \n",
      "of analysis for each constituent in steels. However, IS : 228-1959* \n",
      "version has been retained for the analysis of pig iron and cast iron \n",
      "till a separate standard for analysis of pig iron and cast iron is \n",
      "published. \n",
      "0.2.1 This revision of IS : 228 (Part 6 )-1974t has been undertaken \n",
      "on the basis of experience gained during the implementation of the \n",
      "standard by the manufacturers and testing laboratories. \n",
      "0.3 In this revision, major modifications are: \n",
      "a) scope of the method has been modified by lowering the limit \n",
      "for determination of chromium from 0â5 to 0â1 percent; \n",
      "-.\n",
      "\n",
      "\n",
      "\n",
      "###question:\n",
      "4. What was the purpose of the revision mentioned?\n",
      "\n",
      "###answer:\n",
      "To update the method of chemical analysis</s>\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "------------------\n",
      "<s>###Instruction:\n",
      "below context is from 228_4.pdf, answer the folwing questions based on the context given \n",
      "\n",
      "\n",
      "###context:\n",
      "Context:\n",
      "IS : â228 ( Part 4 ) - 1987 \n",
      "Indian Standard \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 4 DETERYlNATlON OF TOTAL CARBON \n",
      "BY GARVIMETRIC METHOD \n",
      "(FOR CARBON > O-1 PERCENT ) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 4 ) (Third R cvision ) was adopted I)y \n",
      "the Indian Standards Institution on 16 January 1987, afirr the draft \n",
      "finalized by the Methods of Chemical Analysis of Pcrrous Metals \n",
      "Sectional Committre had been approved by the Structural and Mct;~ls \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemical analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "IS t \n",
      "Indian Standard 228 ( Part 5 ) - 1987 \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 6 DETERMINATION OF NICKEL BY \n",
      "DIMETHYLGLYOXIME ( GRAVIMETRIC ) METHOD \n",
      "( FOR NICKEL > 0â1 PERCENT) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 5 ) ( Third Revision ) was adopted by \n",
      "the Indian Standards Institution on 16 January 1987, after the draft \n",
      "finalized by the Methods of Chemical Analysis of Ferrous Metals \n",
      "Sectional Committee had been approved by the Strtictural and Metals \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemial analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "Accordingly, revision of IS : 228 was \n",
      "taken-up again and new series on methods of chemical analysis of \n",
      "steels including high alloy steels was published in various parts as \n",
      "IS : 228 ( Parts 1 to 13 ) ( see Appendix A ) covering separate method \n",
      "of analysis for each constituent in steels. However, IS : 228-1959* \n",
      "version has been retained for the analysis of pig iron and cast iron \n",
      "till a separate standard for analysis of pig iron and cast iron is \n",
      "published. \n",
      "0.2.1 This revision of IS : 228 (Part 6 )-1974t has been undertaken \n",
      "on the basis of experience gained during the implementation of the \n",
      "standard by the manufacturers and testing laboratories. \n",
      "0.3 In this revision, major modifications are: \n",
      "a) scope of the method has been modified by lowering the limit \n",
      "for determination of chromium from 0â5 to 0â1 percent; \n",
      "-.\n",
      "\n",
      "\n",
      "\n",
      "###question:\n",
      "5. What materials were covered in the original version of IS : 228?\n",
      "\n",
      "###answer:\n",
      "Pig iron, cast iron, and plain carbon and low alloy steels</s>\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "------------------\n",
      "<s>###Instruction:\n",
      "below context is from 228_4.pdf, answer the folwing questions based on the context given \n",
      "\n",
      "\n",
      "###context:\n",
      "Context:\n",
      "IS : â228 ( Part 4 ) - 1987 \n",
      "Indian Standard \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 4 DETERYlNATlON OF TOTAL CARBON \n",
      "BY GARVIMETRIC METHOD \n",
      "(FOR CARBON > O-1 PERCENT ) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 4 ) (Third R cvision ) was adopted I)y \n",
      "the Indian Standards Institution on 16 January 1987, afirr the draft \n",
      "finalized by the Methods of Chemical Analysis of Pcrrous Metals \n",
      "Sectional Committre had been approved by the Structural and Mct;~ls \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemical analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "IS t \n",
      "Indian Standard 228 ( Part 5 ) - 1987 \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 6 DETERMINATION OF NICKEL BY \n",
      "DIMETHYLGLYOXIME ( GRAVIMETRIC ) METHOD \n",
      "( FOR NICKEL > 0â1 PERCENT) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 5 ) ( Third Revision ) was adopted by \n",
      "the Indian Standards Institution on 16 January 1987, after the draft \n",
      "finalized by the Methods of Chemical Analysis of Ferrous Metals \n",
      "Sectional Committee had been approved by the Strtictural and Metals \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemial analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "Accordingly, revision of IS : 228 was \n",
      "taken-up again and new series on methods of chemical analysis of \n",
      "steels including high alloy steels was published in various parts as \n",
      "IS : 228 ( Parts 1 to 13 ) ( see Appendix A ) covering separate method \n",
      "of analysis for each constituent in steels. However, IS : 228-1959* \n",
      "version has been retained for the analysis of pig iron and cast iron \n",
      "till a separate standard for analysis of pig iron and cast iron is \n",
      "published. \n",
      "0.2.1 This revision of IS : 228 (Part 6 )-1974t has been undertaken \n",
      "on the basis of experience gained during the implementation of the \n",
      "standard by the manufacturers and testing laboratories. \n",
      "0.3 In this revision, major modifications are: \n",
      "a) scope of the method has been modified by lowering the limit \n",
      "for determination of chromium from 0â5 to 0â1 percent; \n",
      "-.\n",
      "\n",
      "\n",
      "\n",
      "###question:\n",
      "6. Why was a separate standard retained for pig iron and cast iron?\n",
      "\n",
      "###answer:\n",
      "Until a separate revision was undertaken for their analysis</s>\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "------------------\n",
      "<s>###Instruction:\n",
      "below context is from 228_4.pdf, answer the folwing questions based on the context given \n",
      "\n",
      "\n",
      "###context:\n",
      "Context:\n",
      "IS : â228 ( Part 4 ) - 1987 \n",
      "Indian Standard \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 4 DETERYlNATlON OF TOTAL CARBON \n",
      "BY GARVIMETRIC METHOD \n",
      "(FOR CARBON > O-1 PERCENT ) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 4 ) (Third R cvision ) was adopted I)y \n",
      "the Indian Standards Institution on 16 January 1987, afirr the draft \n",
      "finalized by the Methods of Chemical Analysis of Pcrrous Metals \n",
      "Sectional Committre had been approved by the Structural and Mct;~ls \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemical analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "IS t \n",
      "Indian Standard 228 ( Part 5 ) - 1987 \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 6 DETERMINATION OF NICKEL BY \n",
      "DIMETHYLGLYOXIME ( GRAVIMETRIC ) METHOD \n",
      "( FOR NICKEL > 0â1 PERCENT) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 5 ) ( Third Revision ) was adopted by \n",
      "the Indian Standards Institution on 16 January 1987, after the draft \n",
      "finalized by the Methods of Chemical Analysis of Ferrous Metals \n",
      "Sectional Committee had been approved by the Strtictural and Metals \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemial analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "Accordingly, revision of IS : 228 was \n",
      "taken-up again and new series on methods of chemical analysis of \n",
      "steels including high alloy steels was published in various parts as \n",
      "IS : 228 ( Parts 1 to 13 ) ( see Appendix A ) covering separate method \n",
      "of analysis for each constituent in steels. However, IS : 228-1959* \n",
      "version has been retained for the analysis of pig iron and cast iron \n",
      "till a separate standard for analysis of pig iron and cast iron is \n",
      "published. \n",
      "0.2.1 This revision of IS : 228 (Part 6 )-1974t has been undertaken \n",
      "on the basis of experience gained during the implementation of the \n",
      "standard by the manufacturers and testing laboratories. \n",
      "0.3 In this revision, major modifications are: \n",
      "a) scope of the method has been modified by lowering the limit \n",
      "for determination of chromium from 0â5 to 0â1 percent; \n",
      "-.\n",
      "\n",
      "\n",
      "\n",
      "###question:\n",
      "7. What experience was the revision based on?\n",
      "\n",
      "###answer:\n",
      "Experience gained by manufacturers and testing laboratories</s>\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "------------------\n",
      "<s>###Instruction:\n",
      "below context is from 228_4.pdf, answer the folwing questions based on the context given \n",
      "\n",
      "\n",
      "###context:\n",
      "Context:\n",
      "IS : â228 ( Part 4 ) - 1987 \n",
      "Indian Standard \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 4 DETERYlNATlON OF TOTAL CARBON \n",
      "BY GARVIMETRIC METHOD \n",
      "(FOR CARBON > O-1 PERCENT ) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 4 ) (Third R cvision ) was adopted I)y \n",
      "the Indian Standards Institution on 16 January 1987, afirr the draft \n",
      "finalized by the Methods of Chemical Analysis of Pcrrous Metals \n",
      "Sectional Committre had been approved by the Structural and Mct;~ls \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemical analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "IS t \n",
      "Indian Standard 228 ( Part 5 ) - 1987 \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 6 DETERMINATION OF NICKEL BY \n",
      "DIMETHYLGLYOXIME ( GRAVIMETRIC ) METHOD \n",
      "( FOR NICKEL > 0â1 PERCENT) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 5 ) ( Third Revision ) was adopted by \n",
      "the Indian Standards Institution on 16 January 1987, after the draft \n",
      "finalized by the Methods of Chemical Analysis of Ferrous Metals \n",
      "Sectional Committee had been approved by the Strtictural and Metals \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemial analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "Accordingly, revision of IS : 228 was \n",
      "taken-up again and new series on methods of chemical analysis of \n",
      "steels including high alloy steels was published in various parts as \n",
      "IS : 228 ( Parts 1 to 13 ) ( see Appendix A ) covering separate method \n",
      "of analysis for each constituent in steels. However, IS : 228-1959* \n",
      "version has been retained for the analysis of pig iron and cast iron \n",
      "till a separate standard for analysis of pig iron and cast iron is \n",
      "published. \n",
      "0.2.1 This revision of IS : 228 (Part 6 )-1974t has been undertaken \n",
      "on the basis of experience gained during the implementation of the \n",
      "standard by the manufacturers and testing laboratories. \n",
      "0.3 In this revision, major modifications are: \n",
      "a) scope of the method has been modified by lowering the limit \n",
      "for determination of chromium from 0â5 to 0â1 percent; \n",
      "-.\n",
      "\n",
      "\n",
      "\n",
      "###question:\n",
      "8. What updates were made in the revised method?\n",
      "\n",
      "###answer:\n",
      "The method of chemical analysis was updated</s>\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "------------------\n",
      "<s>###Instruction:\n",
      "below context is from 228_4.pdf, answer the folwing questions based on the context given \n",
      "\n",
      "\n",
      "###context:\n",
      "Context:\n",
      "IS : â228 ( Part 4 ) - 1987 \n",
      "Indian Standard \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 4 DETERYlNATlON OF TOTAL CARBON \n",
      "BY GARVIMETRIC METHOD \n",
      "(FOR CARBON > O-1 PERCENT ) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 4 ) (Third R cvision ) was adopted I)y \n",
      "the Indian Standards Institution on 16 January 1987, afirr the draft \n",
      "finalized by the Methods of Chemical Analysis of Pcrrous Metals \n",
      "Sectional Committre had been approved by the Structural and Mct;~ls \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemical analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "IS t \n",
      "Indian Standard 228 ( Part 5 ) - 1987 \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 6 DETERMINATION OF NICKEL BY \n",
      "DIMETHYLGLYOXIME ( GRAVIMETRIC ) METHOD \n",
      "( FOR NICKEL > 0â1 PERCENT) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 5 ) ( Third Revision ) was adopted by \n",
      "the Indian Standards Institution on 16 January 1987, after the draft \n",
      "finalized by the Methods of Chemical Analysis of Ferrous Metals \n",
      "Sectional Committee had been approved by the Strtictural and Metals \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemial analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "Accordingly, revision of IS : 228 was \n",
      "taken-up again and new series on methods of chemical analysis of \n",
      "steels including high alloy steels was published in various parts as \n",
      "IS : 228 ( Parts 1 to 13 ) ( see Appendix A ) covering separate method \n",
      "of analysis for each constituent in steels. However, IS : 228-1959* \n",
      "version has been retained for the analysis of pig iron and cast iron \n",
      "till a separate standard for analysis of pig iron and cast iron is \n",
      "published. \n",
      "0.2.1 This revision of IS : 228 (Part 6 )-1974t has been undertaken \n",
      "on the basis of experience gained during the implementation of the \n",
      "standard by the manufacturers and testing laboratories. \n",
      "0.3 In this revision, major modifications are: \n",
      "a) scope of the method has been modified by lowering the limit \n",
      "for determination of chromium from 0â5 to 0â1 percent; \n",
      "-.\n",
      "\n",
      "\n",
      "\n",
      "###question:\n",
      "9. What is the scope of the standard?\n",
      "\n",
      "###answer:\n",
      "Determination of total carbon content in plain carbon, low alloy, and high alloy steels (Part 4)</s>\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "------------------\n",
      "<s>###Instruction:\n",
      "below context is from 228_4.pdf, answer the folwing questions based on the context given \n",
      "\n",
      "\n",
      "###context:\n",
      "Context:\n",
      "IS : â228 ( Part 4 ) - 1987 \n",
      "Indian Standard \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 4 DETERYlNATlON OF TOTAL CARBON \n",
      "BY GARVIMETRIC METHOD \n",
      "(FOR CARBON > O-1 PERCENT ) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 4 ) (Third R cvision ) was adopted I)y \n",
      "the Indian Standards Institution on 16 January 1987, afirr the draft \n",
      "finalized by the Methods of Chemical Analysis of Pcrrous Metals \n",
      "Sectional Committre had been approved by the Structural and Mct;~ls \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemical analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "IS t \n",
      "Indian Standard 228 ( Part 5 ) - 1987 \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 6 DETERMINATION OF NICKEL BY \n",
      "DIMETHYLGLYOXIME ( GRAVIMETRIC ) METHOD \n",
      "( FOR NICKEL > 0â1 PERCENT) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 5 ) ( Third Revision ) was adopted by \n",
      "the Indian Standards Institution on 16 January 1987, after the draft \n",
      "finalized by the Methods of Chemical Analysis of Ferrous Metals \n",
      "Sectional Committee had been approved by the Strtictural and Metals \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemial analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "Accordingly, revision of IS : 228 was \n",
      "taken-up again and new series on methods of chemical analysis of \n",
      "steels including high alloy steels was published in various parts as \n",
      "IS : 228 ( Parts 1 to 13 ) ( see Appendix A ) covering separate method \n",
      "of analysis for each constituent in steels. However, IS : 228-1959* \n",
      "version has been retained for the analysis of pig iron and cast iron \n",
      "till a separate standard for analysis of pig iron and cast iron is \n",
      "published. \n",
      "0.2.1 This revision of IS : 228 (Part 6 )-1974t has been undertaken \n",
      "on the basis of experience gained during the implementation of the \n",
      "standard by the manufacturers and testing laboratories. \n",
      "0.3 In this revision, major modifications are: \n",
      "a) scope of the method has been modified by lowering the limit \n",
      "for determination of chromium from 0â5 to 0â1 percent; \n",
      "-.\n",
      "\n",
      "\n",
      "\n",
      "###question:\n",
      "10. What temperature is recommended for complete combustion?\n",
      "\n",
      "###answer:\n",
      "1250Â°C for high chromium and high nickel steels</s>\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "------------------\n",
      "<s>###Instruction:\n",
      "below context is from 228_4.pdf, answer the folwing questions based on the context given \n",
      "\n",
      "\n",
      "###context:\n",
      "Context:\n",
      "IS : â228 ( Part 4 ) - 1987 \n",
      "Indian Standard \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 4 DETERYlNATlON OF TOTAL CARBON \n",
      "BY GARVIMETRIC METHOD \n",
      "(FOR CARBON > O-1 PERCENT ) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 4 ) (Third R cvision ) was adopted I)y \n",
      "the Indian Standards Institution on 16 January 1987, afirr the draft \n",
      "finalized by the Methods of Chemical Analysis of Pcrrous Metals \n",
      "Sectional Committre had been approved by the Structural and Mct;~ls \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemical analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "IS t \n",
      "Indian Standard 228 ( Part 5 ) - 1987 \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 6 DETERMINATION OF NICKEL BY \n",
      "DIMETHYLGLYOXIME ( GRAVIMETRIC ) METHOD \n",
      "( FOR NICKEL > 0â1 PERCENT) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 5 ) ( Third Revision ) was adopted by \n",
      "the Indian Standards Institution on 16 January 1987, after the draft \n",
      "finalized by the Methods of Chemical Analysis of Ferrous Metals \n",
      "Sectional Committee had been approved by the Strtictural and Metals \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemial analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "Accordingly, revision of IS : 228 was \n",
      "taken-up again and new series on methods of chemical analysis of \n",
      "steels including high alloy steels was published in various parts as \n",
      "IS : 228 ( Parts 1 to 13 ) ( see Appendix A ) covering separate method \n",
      "of analysis for each constituent in steels. However, IS : 228-1959* \n",
      "version has been retained for the analysis of pig iron and cast iron \n",
      "till a separate standard for analysis of pig iron and cast iron is \n",
      "published. \n",
      "0.2.1 This revision of IS : 228 (Part 6 )-1974t has been undertaken \n",
      "on the basis of experience gained during the implementation of the \n",
      "standard by the manufacturers and testing laboratories. \n",
      "0.3 In this revision, major modifications are: \n",
      "a) scope of the method has been modified by lowering the limit \n",
      "for determination of chromium from 0â5 to 0â1 percent; \n",
      "-.\n",
      "\n",
      "\n",
      "\n",
      "###question:\n",
      "11. What is the recommended weight range for the test sample?\n",
      "\n",
      "###answer:\n",
      "2.0 to 3.0 g</s>\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "------------------\n",
      "<s>###Instruction:\n",
      "below context is from 228_4.pdf, answer the folwing questions based on the context given \n",
      "\n",
      "\n",
      "###context:\n",
      "Context:\n",
      "IS : â228 ( Part 4 ) - 1987 \n",
      "Indian Standard \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 4 DETERYlNATlON OF TOTAL CARBON \n",
      "BY GARVIMETRIC METHOD \n",
      "(FOR CARBON > O-1 PERCENT ) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 4 ) (Third R cvision ) was adopted I)y \n",
      "the Indian Standards Institution on 16 January 1987, afirr the draft \n",
      "finalized by the Methods of Chemical Analysis of Pcrrous Metals \n",
      "Sectional Committre had been approved by the Structural and Mct;~ls \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemical analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "IS t \n",
      "Indian Standard 228 ( Part 5 ) - 1987 \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 6 DETERMINATION OF NICKEL BY \n",
      "DIMETHYLGLYOXIME ( GRAVIMETRIC ) METHOD \n",
      "( FOR NICKEL > 0â1 PERCENT) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 5 ) ( Third Revision ) was adopted by \n",
      "the Indian Standards Institution on 16 January 1987, after the draft \n",
      "finalized by the Methods of Chemical Analysis of Ferrous Metals \n",
      "Sectional Committee had been approved by the Strtictural and Metals \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemial analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "Accordingly, revision of IS : 228 was \n",
      "taken-up again and new series on methods of chemical analysis of \n",
      "steels including high alloy steels was published in various parts as \n",
      "IS : 228 ( Parts 1 to 13 ) ( see Appendix A ) covering separate method \n",
      "of analysis for each constituent in steels. However, IS : 228-1959* \n",
      "version has been retained for the analysis of pig iron and cast iron \n",
      "till a separate standard for analysis of pig iron and cast iron is \n",
      "published. \n",
      "0.2.1 This revision of IS : 228 (Part 6 )-1974t has been undertaken \n",
      "on the basis of experience gained during the implementation of the \n",
      "standard by the manufacturers and testing laboratories. \n",
      "0.3 In this revision, major modifications are: \n",
      "a) scope of the method has been modified by lowering the limit \n",
      "for determination of chromium from 0â5 to 0â1 percent; \n",
      "-.\n",
      "\n",
      "\n",
      "\n",
      "###question:\n",
      "12. How should the sample be spread in the combustion boat?\n",
      "\n",
      "###answer:\n",
      "Evenly over the top of the covered alumina boat</s>\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "------------------\n",
      "<s>###Instruction:\n",
      "below context is from 228_4.pdf, answer the folwing questions based on the context given \n",
      "\n",
      "\n",
      "###context:\n",
      "Context:\n",
      "IS : â228 ( Part 4 ) - 1987 \n",
      "Indian Standard \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 4 DETERYlNATlON OF TOTAL CARBON \n",
      "BY GARVIMETRIC METHOD \n",
      "(FOR CARBON > O-1 PERCENT ) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 4 ) (Third R cvision ) was adopted I)y \n",
      "the Indian Standards Institution on 16 January 1987, afirr the draft \n",
      "finalized by the Methods of Chemical Analysis of Pcrrous Metals \n",
      "Sectional Committre had been approved by the Structural and Mct;~ls \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemical analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "IS t \n",
      "Indian Standard 228 ( Part 5 ) - 1987 \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 6 DETERMINATION OF NICKEL BY \n",
      "DIMETHYLGLYOXIME ( GRAVIMETRIC ) METHOD \n",
      "( FOR NICKEL > 0â1 PERCENT) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 5 ) ( Third Revision ) was adopted by \n",
      "the Indian Standards Institution on 16 January 1987, after the draft \n",
      "finalized by the Methods of Chemical Analysis of Ferrous Metals \n",
      "Sectional Committee had been approved by the Strtictural and Metals \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemial analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "Accordingly, revision of IS : 228 was \n",
      "taken-up again and new series on methods of chemical analysis of \n",
      "steels including high alloy steels was published in various parts as \n",
      "IS : 228 ( Parts 1 to 13 ) ( see Appendix A ) covering separate method \n",
      "of analysis for each constituent in steels. However, IS : 228-1959* \n",
      "version has been retained for the analysis of pig iron and cast iron \n",
      "till a separate standard for analysis of pig iron and cast iron is \n",
      "published. \n",
      "0.2.1 This revision of IS : 228 (Part 6 )-1974t has been undertaken \n",
      "on the basis of experience gained during the implementation of the \n",
      "standard by the manufacturers and testing laboratories. \n",
      "0.3 In this revision, major modifications are: \n",
      "a) scope of the method has been modified by lowering the limit \n",
      "for determination of chromium from 0â5 to 0â1 percent; \n",
      "-.\n",
      "\n",
      "\n",
      "\n",
      "###question:\n",
      "13. What flow rate of oxygen is recommended during combustion?\n",
      "\n",
      "###answer:\n",
      "Initially 800 to 1000 ml/min, then reduced to 400 to 500 ml/min</s>\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "------------------\n",
      "<s>###Instruction:\n",
      "below context is from 228_4.pdf, answer the folwing questions based on the context given \n",
      "\n",
      "\n",
      "###context:\n",
      "Context:\n",
      "IS : â228 ( Part 4 ) - 1987 \n",
      "Indian Standard \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 4 DETERYlNATlON OF TOTAL CARBON \n",
      "BY GARVIMETRIC METHOD \n",
      "(FOR CARBON > O-1 PERCENT ) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 4 ) (Third R cvision ) was adopted I)y \n",
      "the Indian Standards Institution on 16 January 1987, afirr the draft \n",
      "finalized by the Methods of Chemical Analysis of Pcrrous Metals \n",
      "Sectional Committre had been approved by the Structural and Mct;~ls \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemical analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "IS t \n",
      "Indian Standard 228 ( Part 5 ) - 1987 \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 6 DETERMINATION OF NICKEL BY \n",
      "DIMETHYLGLYOXIME ( GRAVIMETRIC ) METHOD \n",
      "( FOR NICKEL > 0â1 PERCENT) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 5 ) ( Third Revision ) was adopted by \n",
      "the Indian Standards Institution on 16 January 1987, after the draft \n",
      "finalized by the Methods of Chemical Analysis of Ferrous Metals \n",
      "Sectional Committee had been approved by the Strtictural and Metals \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemial analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "Accordingly, revision of IS : 228 was \n",
      "taken-up again and new series on methods of chemical analysis of \n",
      "steels including high alloy steels was published in various parts as \n",
      "IS : 228 ( Parts 1 to 13 ) ( see Appendix A ) covering separate method \n",
      "of analysis for each constituent in steels. However, IS : 228-1959* \n",
      "version has been retained for the analysis of pig iron and cast iron \n",
      "till a separate standard for analysis of pig iron and cast iron is \n",
      "published. \n",
      "0.2.1 This revision of IS : 228 (Part 6 )-1974t has been undertaken \n",
      "on the basis of experience gained during the implementation of the \n",
      "standard by the manufacturers and testing laboratories. \n",
      "0.3 In this revision, major modifications are: \n",
      "a) scope of the method has been modified by lowering the limit \n",
      "for determination of chromium from 0â5 to 0â1 percent; \n",
      "-.\n",
      "\n",
      "\n",
      "\n",
      "###question:\n",
      "14. What is the purpose of reducing the oxygen flow rate?\n",
      "\n",
      "###answer:\n",
      "To sweep out the carbon dioxide formed during combustion</s>\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "------------------\n",
      "<s>###Instruction:\n",
      "below context is from 228_4.pdf, answer the folwing questions based on the context given \n",
      "\n",
      "\n",
      "###context:\n",
      "Context:\n",
      "IS : â228 ( Part 4 ) - 1987 \n",
      "Indian Standard \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 4 DETERYlNATlON OF TOTAL CARBON \n",
      "BY GARVIMETRIC METHOD \n",
      "(FOR CARBON > O-1 PERCENT ) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 4 ) (Third R cvision ) was adopted I)y \n",
      "the Indian Standards Institution on 16 January 1987, afirr the draft \n",
      "finalized by the Methods of Chemical Analysis of Pcrrous Metals \n",
      "Sectional Committre had been approved by the Structural and Mct;~ls \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemical analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "IS t \n",
      "Indian Standard 228 ( Part 5 ) - 1987 \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 6 DETERMINATION OF NICKEL BY \n",
      "DIMETHYLGLYOXIME ( GRAVIMETRIC ) METHOD \n",
      "( FOR NICKEL > 0â1 PERCENT) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 5 ) ( Third Revision ) was adopted by \n",
      "the Indian Standards Institution on 16 January 1987, after the draft \n",
      "finalized by the Methods of Chemical Analysis of Ferrous Metals \n",
      "Sectional Committee had been approved by the Strtictural and Metals \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemial analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "Accordingly, revision of IS : 228 was \n",
      "taken-up again and new series on methods of chemical analysis of \n",
      "steels including high alloy steels was published in various parts as \n",
      "IS : 228 ( Parts 1 to 13 ) ( see Appendix A ) covering separate method \n",
      "of analysis for each constituent in steels. However, IS : 228-1959* \n",
      "version has been retained for the analysis of pig iron and cast iron \n",
      "till a separate standard for analysis of pig iron and cast iron is \n",
      "published. \n",
      "0.2.1 This revision of IS : 228 (Part 6 )-1974t has been undertaken \n",
      "on the basis of experience gained during the implementation of the \n",
      "standard by the manufacturers and testing laboratories. \n",
      "0.3 In this revision, major modifications are: \n",
      "a) scope of the method has been modified by lowering the limit \n",
      "for determination of chromium from 0â5 to 0â1 percent; \n",
      "-.\n",
      "\n",
      "\n",
      "\n",
      "###question:\n",
      "15. How is the increase in weight of the absorption bulb calculated?\n",
      "\n",
      "###answer:\n",
      "By subtracting the increase in weight of the blank bulb from that of the sample bulb</s>\n",
      "---------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 6 examples [00:00, 968.10 examples/s]\n",
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "<s>###Instruction:\n",
      "below context is from 228_6.pdf, answer the folwing questions based on the context given \n",
      "\n",
      "\n",
      "###context:\n",
      "Context:\n",
      "IS : â228 ( Part 4 ) - 1987 \n",
      "Indian Standard \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 4 DETERYlNATlON OF TOTAL CARBON \n",
      "BY GARVIMETRIC METHOD \n",
      "(FOR CARBON > O-1 PERCENT ) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 4 ) (Third R cvision ) was adopted I)y \n",
      "the Indian Standards Institution on 16 January 1987, afirr the draft \n",
      "finalized by the Methods of Chemical Analysis of Pcrrous Metals \n",
      "Sectional Committre had been approved by the Structural and Mct;~ls \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemical analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "IS t \n",
      "Indian Standard 228 ( Part 5 ) - 1987 \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 6 DETERMINATION OF NICKEL BY \n",
      "DIMETHYLGLYOXIME ( GRAVIMETRIC ) METHOD \n",
      "( FOR NICKEL > 0â1 PERCENT) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 5 ) ( Third Revision ) was adopted by \n",
      "the Indian Standards Institution on 16 January 1987, after the draft \n",
      "finalized by the Methods of Chemical Analysis of Ferrous Metals \n",
      "Sectional Committee had been approved by the Strtictural and Metals \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemial analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "Accordingly, revision of IS : 228 was \n",
      "taken-up again and new series on methods of chemical analysis of \n",
      "steels including high alloy steels was published in various parts as \n",
      "IS : 228 ( Parts 1 to 13 ) ( see Appendix A ) covering separate method \n",
      "of analysis for each constituent in steels. However, IS : 228-1959* \n",
      "version has been retained for the analysis of pig iron and cast iron \n",
      "till a separate standard for analysis of pig iron and cast iron is \n",
      "published. \n",
      "0.2.1 This revision of IS : 228 (Part 6 )-1974t has been undertaken \n",
      "on the basis of experience gained during the implementation of the \n",
      "standard by the manufacturers and testing laboratories. \n",
      "0.3 In this revision, major modifications are: \n",
      "a) scope of the method has been modified by lowering the limit \n",
      "for determination of chromium from 0â5 to 0â1 percent; \n",
      "-.\n",
      "\n",
      "\n",
      "\n",
      "###question:\n",
      "What is the reproducibility range for chromium content at 1 to 5 percent?\n",
      "\n",
      "###answer:\n",
      "Reproducibility is Â±0.120 percent.</s>\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "------------------\n",
      "<s>###Instruction:\n",
      "below context is from 228_6.pdf, answer the folwing questions based on the context given \n",
      "\n",
      "\n",
      "###context:\n",
      "Context:\n",
      "IS : â228 ( Part 4 ) - 1987 \n",
      "Indian Standard \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 4 DETERYlNATlON OF TOTAL CARBON \n",
      "BY GARVIMETRIC METHOD \n",
      "(FOR CARBON > O-1 PERCENT ) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 4 ) (Third R cvision ) was adopted I)y \n",
      "the Indian Standards Institution on 16 January 1987, afirr the draft \n",
      "finalized by the Methods of Chemical Analysis of Pcrrous Metals \n",
      "Sectional Committre had been approved by the Structural and Mct;~ls \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemical analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "IS t \n",
      "Indian Standard 228 ( Part 5 ) - 1987 \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 6 DETERMINATION OF NICKEL BY \n",
      "DIMETHYLGLYOXIME ( GRAVIMETRIC ) METHOD \n",
      "( FOR NICKEL > 0â1 PERCENT) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 5 ) ( Third Revision ) was adopted by \n",
      "the Indian Standards Institution on 16 January 1987, after the draft \n",
      "finalized by the Methods of Chemical Analysis of Ferrous Metals \n",
      "Sectional Committee had been approved by the Strtictural and Metals \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemial analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "Accordingly, revision of IS : 228 was \n",
      "taken-up again and new series on methods of chemical analysis of \n",
      "steels including high alloy steels was published in various parts as \n",
      "IS : 228 ( Parts 1 to 13 ) ( see Appendix A ) covering separate method \n",
      "of analysis for each constituent in steels. However, IS : 228-1959* \n",
      "version has been retained for the analysis of pig iron and cast iron \n",
      "till a separate standard for analysis of pig iron and cast iron is \n",
      "published. \n",
      "0.2.1 This revision of IS : 228 (Part 6 )-1974t has been undertaken \n",
      "on the basis of experience gained during the implementation of the \n",
      "standard by the manufacturers and testing laboratories. \n",
      "0.3 In this revision, major modifications are: \n",
      "a) scope of the method has been modified by lowering the limit \n",
      "for determination of chromium from 0â5 to 0â1 percent; \n",
      "-.\n",
      "\n",
      "\n",
      "\n",
      "###question:\n",
      "What is the reproducibility range for chromium content at 5 percent and above?\n",
      "\n",
      "###answer:\n",
      "Reproducibility is Â±0.20 percent.</s>\n",
      "---------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:342: UserWarning: You passed `packing=True` to the SFTTrainer, and you are training your model with `max_steps` strategy. The dataset will be iterated until the `max_steps` are reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "\n",
    "max_seq_length = 256\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    peft_config = peft_config,\n",
    "    max_seq_length=max_seq_length,\n",
    "    tokenizer = tokenizer,\n",
    "    formatting_func=create_prompt,\n",
    "    packing = True,\n",
    "    args = args,\n",
    "    train_dataset = selected_dataset_dict[\"train\"],\n",
    "    eval_dataset= selected_dataset_dict[\"test\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 10:41, Epoch 30/34]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.818500</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.195900</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.123500</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.076200</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.057600</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100, training_loss=0.389068004488945, metrics={'train_runtime': 647.7118, 'train_samples_per_second': 2.47, 'train_steps_per_second': 0.154, 'total_flos': 1.655541325627392e+16, 'train_loss': 0.389068004488945, 'epoch': 30.76923076923077})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt (no context)\n",
    "intstructions_string = f\"\"\" you are a textbot that helps in finding answers to questions in the research papers, blogs,pdf's or any text context.\n",
    "end all responses with a signature -yourbot\n",
    "\n",
    "please answer the following question\n",
    "\"\"\"\n",
    "prompt_template = lambda question: f'''[INST] {intstructions_string} \\n{question} \\n[/INST]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST]  you are a textbot that helps in finding answers to questions in the research papers, blogs,pdf's or any text context.\n",
      "end all responses with a signature -yourbot\n",
      "\n",
      "please answer the following question\n",
      " \n",
      "When was the mentoined standard adopted? \n",
      "[/INST]\n"
     ]
    }
   ],
   "source": [
    "question = \"When was the mentoined standard adopted?\"\n",
    "\n",
    "prompt = prompt_template(question)\n",
    "print(prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> [INST]  you are a textbot that helps in finding answers to questions in the research papers, blogs,pdf's or any text context.\n",
      "end all responses with a signature -yourbot\n",
      "\n",
      "please answer the following question\n",
      " \n",
      "When was the mentoined standard adopted? \n",
      "[/INST] In order to answer your question, I would need to have the context of the specific standard you are referring to. Could you please provide the name or the publication number of the standard you are interested in?\n",
      "\n",
      "###YourBot</s>\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), max_new_tokens=280)\n",
    "\n",
    "print(tokenizer.batch_decode(outputs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt (no context)\n",
    "intstructions_string = f\"\"\" you are a textbot that helps in finding answers to questions in the research papers, blogs,pdf's or any text context.\n",
    "end all responses with a signature -yourbot\n",
    "\n",
    "please answer the following question\n",
    "\"\"\"\n",
    "prompt_template_w_context = lambda context, question: f'''[INST] {intstructions_string}\n",
    "\n",
    "{context}\n",
    "\n",
    "Please answer to the following question. Use the context above if it is helpful.\n",
    "\n",
    "{question}\n",
    "\n",
    "[/INST]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST]  you are a textbot that helps in finding answers to questions in the research papers, blogs,pdf's or any text context.\n",
      "end all responses with a signature -yourbot\n",
      "\n",
      "please answer the following question\n",
      "\n",
      "\n",
      "Context:\n",
      "IS : â228 ( Part 4 ) - 1987 \n",
      "Indian Standard \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 4 DETERYlNATlON OF TOTAL CARBON \n",
      "BY GARVIMETRIC METHOD \n",
      "(FOR CARBON > O-1 PERCENT ) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 4 ) (Third R cvision ) was adopted I)y \n",
      "the Indian Standards Institution on 16 January 1987, afirr the draft \n",
      "finalized by the Methods of Chemical Analysis of Pcrrous Metals \n",
      "Sectional Committre had been approved by the Structural and Mct;~ls \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemical analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "IS t \n",
      "Indian Standard 228 ( Part 5 ) - 1987 \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 6 DETERMINATION OF NICKEL BY \n",
      "DIMETHYLGLYOXIME ( GRAVIMETRIC ) METHOD \n",
      "( FOR NICKEL > 0â1 PERCENT) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 5 ) ( Third Revision ) was adopted by \n",
      "the Indian Standards Institution on 16 January 1987, after the draft \n",
      "finalized by the Methods of Chemical Analysis of Ferrous Metals \n",
      "Sectional Committee had been approved by the Strtictural and Metals \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemial analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "Accordingly, revision of IS : 228 was \n",
      "taken-up again and new series on methods of chemical analysis of \n",
      "steels including high alloy steels was published in various parts as \n",
      "IS : 228 ( Parts 1 to 13 ) ( see Appendix A ) covering separate method \n",
      "of analysis for each constituent in steels. However, IS : 228-1959* \n",
      "version has been retained for the analysis of pig iron and cast iron \n",
      "till a separate standard for analysis of pig iron and cast iron is \n",
      "published. \n",
      "0.2.1 This revision of IS : 228 (Part 6 )-1974t has been undertaken \n",
      "on the basis of experience gained during the implementation of the \n",
      "standard by the manufacturers and testing laboratories. \n",
      "0.3 In this revision, major modifications are: \n",
      "a) scope of the method has been modified by lowering the limit \n",
      "for determination of chromium from 0â5 to 0â1 percent; \n",
      "-.\n",
      "\n",
      "\n",
      "\n",
      "Please answer to the following question. Use the context above if it is helpful.\n",
      "\n",
      "When was the mentoined standard adopted?\n",
      "\n",
      "[/INST]\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template_w_context(context, question)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> [INST]  you are a textbot that helps in finding answers to questions in the research papers, blogs,pdf's or any text context.\n",
      "end all responses with a signature -yourbot\n",
      "\n",
      "please answer the following question\n",
      "\n",
      "\n",
      "Context:\n",
      "IS : â228 ( Part 4 ) - 1987 \n",
      "Indian Standard \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 4 DETERYlNATlON OF TOTAL CARBON \n",
      "BY GARVIMETRIC METHOD \n",
      "(FOR CARBON > O-1 PERCENT ) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 4 ) (Third R cvision ) was adopted I)y \n",
      "the Indian Standards Institution on 16 January 1987, afirr the draft \n",
      "finalized by the Methods of Chemical Analysis of Pcrrous Metals \n",
      "Sectional Committre had been approved by the Structural and Mct;~ls \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemical analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "IS t \n",
      "Indian Standard 228 ( Part 5 ) - 1987 \n",
      "METHODS FOR \n",
      "CHEMICAL ANALYSIS OF STEELS \n",
      "PART 6 DETERMINATION OF NICKEL BY \n",
      "DIMETHYLGLYOXIME ( GRAVIMETRIC ) METHOD \n",
      "( FOR NICKEL > 0â1 PERCENT) \n",
      "( Third Revision ) \n",
      "0. FOREWORD \n",
      "0.1 This Indian Standard ( Part 5 ) ( Third Revision ) was adopted by \n",
      "the Indian Standards Institution on 16 January 1987, after the draft \n",
      "finalized by the Methods of Chemical Analysis of Ferrous Metals \n",
      "Sectional Committee had been approved by the Strtictural and Metals \n",
      "Division Council. \n",
      "0.2 IS : 228, which was issued as a tentative standard in 1952 and \n",
      "revised in 1959, covered the chemial analysis of pig iron, cast iron and \n",
      "plain carbon and low alloy steels.\n",
      "\n",
      "Accordingly, revision of IS : 228 was \n",
      "taken-up again and new series on methods of chemical analysis of \n",
      "steels including high alloy steels was published in various parts as \n",
      "IS : 228 ( Parts 1 to 13 ) ( see Appendix A ) covering separate method \n",
      "of analysis for each constituent in steels. However, IS : 228-1959* \n",
      "version has been retained for the analysis of pig iron and cast iron \n",
      "till a separate standard for analysis of pig iron and cast iron is \n",
      "published. \n",
      "0.2.1 This revision of IS : 228 (Part 6 )-1974t has been undertaken \n",
      "on the basis of experience gained during the implementation of the \n",
      "standard by the manufacturers and testing laboratories. \n",
      "0.3 In this revision, major modifications are: \n",
      "a) scope of the method has been modified by lowering the limit \n",
      "for determination of chromium from 0â5 to 0â1 percent; \n",
      "-.\n",
      "\n",
      "\n",
      "\n",
      "Please answer to the following question. Use the context above if it is helpful.\n",
      "\n",
      "When was the mentoined standard adopted?\n",
      "\n",
      "[/INST] The mentioned standard (IS : 228 (Part 4 )-1987) was adopted on 16 January 1987.</s>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), max_new_tokens=280)\n",
    "\n",
    "print(tokenizer.batch_decode(outputs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(\"KOKO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "merged_model = model.merge_and_unload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> Q: Let g be (11/(-3))/(2/81). Let w = g + 292. What is the tens digit of w?\\nA: 1</s>'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
