{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the instruct_tune_dataset dataset\n",
    "dataset = load_dataset(\"Dobby091/koko\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['pdf_filename', 'context', 'question', 'answer'],\n",
       "        num_rows: 884\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['pdf_filename', 'context', 'question', 'answer'],\n",
       "        num_rows: 222\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(dataset[\"test\"][0])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples: 150\n",
      "Number of test samples: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['pdf_filename', 'context', 'question', 'answer'],\n",
       "        num_rows: 150\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['pdf_filename', 'context', 'question', 'answer'],\n",
       "        num_rows: 2\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Select the first 1000 samples in the train set and the first 200 samples in the test set\n",
    "train_dataset = dataset['train'].select(range(150))\n",
    "test_dataset = dataset['test'].select(range(2))\n",
    "\n",
    "# Create a new `DatasetDict` to store the selected samples\n",
    "selected_dataset_dict = DatasetDict({'train': train_dataset, 'test': test_dataset})\n",
    "\n",
    "# Print the number of samples in each split\n",
    "print(f\"Number of train samples: {len(train_dataset)}\")\n",
    "print(f\"Number of test samples: {len(test_dataset)}\")\n",
    "\n",
    "selected_dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for now lets keep selected dataset as total dataset because of low data\n",
    "# selected_dataset_dict = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install llama-index\n",
    "# !pip install llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings, SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data1/backup/viswaz/Project_K/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/mnt/data1/backup/viswaz/Project_K/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM is explicitly disabled. Using MockLLM.\n"
     ]
    }
   ],
   "source": [
    "# import any embedding model on HF hub (https://huggingface.co/spaces/mteb/leaderboard)\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "# Settings.embed_model = HuggingFaceEmbedding(model_name=\"thenlper/gte-large\") # alternative model\n",
    "\n",
    "Settings.llm = None\n",
    "Settings.chunk_size = 256\n",
    "Settings.chunk_overlap = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['pdf_filename', 'context', 'question', 'answer'],\n",
       "        num_rows: 884\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['pdf_filename', 'context', 'question', 'answer'],\n",
       "        num_rows: 222\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=selected_dataset_dict[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_contexts = list(set(train_dataset['context']))\n",
    "# print(unique_contexts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document, VectorStoreIndex\n",
    "\n",
    "documents = [Document(text=context + '||ENDOFDOC||', id=str(hash(context))) for context in unique_contexts]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(documents)\n",
    "top_k = 3\n",
    "\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=top_k,\n",
    ")\n",
    "\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.5)],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "Indian Standard \n",
      "COLDROLLEDLOWCARBONSTEELSHEETS \n",
      "AND STRIPS-SPECIFICATION \n",
      "( Fourth Revision ) \n",
      "Third Reprint FEBRUARY 199s \n",
      "UDC 669’14’415-122’2 \n",
      "@ BIS 1994 \n",
      "BUR.EAU OF INDIAN STANDARDS \n",
      "MANAK BHAVAN, 9 BAHADUR SHAH ZAFAR MARG \n",
      "NEW DELHI 110002 \n",
      "March 1994 Price Group 4 Wrought Steel Products Sectional Committee, MTD 4 \n",
      "FOREWORD \n",
      "This Indian Standard ( Fourth Revision ) was adopted by the Bureau of Indian Standards, after \n",
      "the draft finalized by the Wrought Steel Products Sectional Committee had been approved by \n",
      "the Metallurgical Engineering Division Council. \n",
      "This standard was first published in 1954 and subsequently revised in 1963, 1973 and 1986. While \n",
      "reviewing the standard in the light of experience gained during these years, the committee decided \n",
      "to revise it toalign with the present practices being followed by the Indian Industry.\n",
      "\n",
      "IS454: 1994 \n",
      "Indian Standard \n",
      "CUTBACK BITUMEN FROM WAXY \n",
      "CRUDE - SPECIFICATION \n",
      "( Second Revision ) \n",
      "UDC 665.745 \n",
      "@ BIS 1994 \n",
      "BUREAU OF INDIAN STANDARDS \n",
      "MANAK BHAVAN, 9 BAHADUR SHAH ZAFAR MARG \n",
      "NEW DELHI 110002 \n",
      "December 1994 PriceGroup 2 Bitumen, Tar and Their Products Sectional Committee, PCD 6 \n",
      "FOREWORD \n",
      "This Indian Standard (Second Revision) was adopted by the Bureau of Indian Standards, after the draft \n",
      "finalized by the Bitumen, Tar and Their Products Sectional Committee had been approved by the \n",
      "Petroleum, Coal and Related Products Division Council. \n",
      "This standard was first published in 1953 and revised in 1961 in order to incorporate references to various \n",
      "methods of tests (IS 1201 to 1220) suitably subsequent to their publication in 1958.\n",
      "\n",
      "Review of Indian Standards \n",
      "Amendments are issued to standards as the need arises on the basis of comments. Standards are also \n",
      "reviewed periodically; a standard along with amendments IS reaffirmed when such review indicates that \n",
      "no changes are needed; if the review indicates that changes are needed, it is taken up for revision. \n",
      "Users of Indian Standards should ascertain that they are in possession of the latest amendments or \n",
      "edition by referring to the latest issue of ‘BIS Handbook’ and ‘Standards Monthly Additions’, \n",
      "This Indian Standard has been developed from Dot No. MTD 4 ( 3566 ), \n",
      "Amendments Issued Since Publication \n",
      "Amend No. Date of Issue Text Affected \n",
      "_I____-_- -_-- \n",
      "BUREAU OF INDIAN STANDARDS \n",
      "Headquarters: \n",
      "Manak Bhavan, 9 Bahadur Shah Zafar Marg, New Delhi 110002 Telegrams : Manaksanstha \n",
      "Telephones : 331 01 31, 331 13 75 ( Common to all offices ) \n",
      "Regional Offices : Telephone \n",
      "Central : Manak Bhavan,\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# query documents\n",
    "query = \"When was this standard adopted?\"\n",
    "response = query_engine.query(query)\n",
    "\n",
    "# reformat response\n",
    "context = \"Context:\\n\"\n",
    "for i in range(top_k):\n",
    "    context = context + response.source_nodes[i].text + \"\\n\\n\"\n",
    "\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['pdf_filename', 'context', 'question', 'answer'],\n",
       "        num_rows: 150\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['pdf_filename', 'context', 'question', 'answer'],\n",
       "        num_rows: 2\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "<s>You are a helpful assistant. The following context is from 228_14.pdf\n",
      "Context: \n",
      "UDC 669.14 : 643,226 1643,942 ) ( Second Reprint SEPTEMBER 1996 ) IS:228(Partl4)-1988 \n",
      "Indian Standard \n",
      "METHODS FOR CHEMICAL ANALYSIS OF STEELS \n",
      "PART 14 DETERMINATION OF CARBON BY THERMAL CONDUCTIVITY METHOD \n",
      "(FOR CARBON 0.005 TO 2.000 PERCENT) \n",
      "I. scope -This standard ( Part 14 ) covers a method for determination of carbon in all types ( \n",
      "steels and alloy steels in the range of 0’005 to 2’000 percent. \n",
      "2. Determination of Carbon by Thermal Conductivity Method \n",
      "2.1 Oofh’ne offhe Method- The sample is burnt in a stream of oxygen in presence of a met; \n",
      "accelerator. The carbon dioxide formed is selectively adsorbed on the molecular sieve at a tempera \n",
      "ture apd released by heating at 300°C. The detector is a thermistor cell which senses the differenc# \n",
      "between thermal conductivity of the carrier gas ( with helium specially for extra-ldw carbon, ant \n",
      "oxygen in other cases ) and that of the carrier gas containing carbpn dioxide. This difference i \n",
      "proportional to carbon content of the sample. \n",
      "3. Reagents \n",
      "3.1 Oxygen ( 01) - 99’6 percent pure, Min. \n",
      "3.2 Helium- 99’5 percent pure, Min. \n",
      "1.3 Ascarite or Soda-Lime - 0’80 mm-2’0 mm. \n",
      ".4 Magnesium Perch/orate - 0’80 mm-20 mm. \n",
      ".S Concentrated Sulphuric Acid ( rd 7 1’84 ) - Conforming to IS : 263-1977 ‘Specification fo \n",
      "ulphuric acid ( second revision )‘. \n",
      ".6 Sulphur Trap - containing manganese dioxide ( MnOt ). \n",
      ",7 Carbon Dioxide Converter - containing copper oxide maintained at 300°C. \n",
      "8 Accelerators - coppei, tin or iron granules, free from carbon and sulphur. \n",
      "9 Crucibles -pre-ignited crucibles of precise dimensions which may be accommodated in \n",
      "mibustion tube of the induction furnace. \n",
      "Apparatus - Any analyser consisting of induction furnace, molecular sieve, chromatographic \n",
      "blumn and thermistor type detector. \n",
      "Sampling - The samples shall be drawn and prepared as prescribed in the relevant Indian \n",
      "Standard. \n",
      "6, Procedure \n",
      "6.1 Standardization \n",
      "6.1 .I Switch on the instrument for 4 hours before analyzing the samples for attaining thermal \n",
      "stability of the cell. \n",
      "6.1.2 Start the flow of purified oxygen gas and pass it continuously through the system at the \n",
      "rate of 1 000 - 1 500 ml/minute. \n",
      "Adopted 22 December 1987 \n",
      "I . @ June 1988. BIS \n",
      "I Gr 1 \n",
      "BUREAU OF INDIAN STANDARDS \n",
      "MANAK BHAVAN. 9 BAHAOUR SHAH ZAFAR MARG \n",
      "NEW OELHI 110002 IS : 228 (Part 44 ) - 1988 \n",
      "6.1.3 Transfer into the pre-ignited crucible 1’00 g standard sample which has a value Of carbon \n",
      "in the range of interest and add 1’0 g accelerator. \n",
      "6.1.4 Insert the crucible into the induction furnace, wait for 30 seconds and start the induction. \n",
      "6.1.5 Note the percentage carbon, and adjust if necessary, the standardization until the certified \n",
      "value of carbon for the standard sample is obtained and with the desired reproducibility. \n",
      "6.2 For Sample \n",
      "6.2.1 Transfer 1 g of accurately weighed sample previQusly washed with organic solvent ( like \n",
      "acetone, benzene or ether) thrice and dried at 100&5”C OF the crucible and add 1’0 g of accelerator. \n",
      "6.2.2 Insert into the induction furnace and proceed until the percentage of carbon is read out. \n",
      "7. Reproducibility - rf, 0’000 2 percent or f 0’5 percent of carbon present whichever is greater. \n",
      "EXPLANATORY NOTE \n",
      "The first revision of IS : 228-1959 covered the chemical analysis of plain carbon and low alloy \n",
      "steels along with pig iron and cast iron. This standard was again revised to make it comprehensive \n",
      "in respect of steel analysis and to exclude pig iron and cast iron analysis which is being covered in 8 \n",
      "separate standard. \n",
      "of steels. The second revision of IS : 228 was issued in parts covering chetnical analysis \n",
      "method. This part ( Part 14 ) covers chemical analysis of ca!bon in steels by thermal conductivity \n",
      "Determination of carbon in steels by infra-red combustion .method is being covered in \n",
      "another part of series of this standard. However, determination of carbon in steels by volumetric \n",
      "and gravimetric methods has been prescribed in Part 1 and Part 4 of this standard. The other parts \n",
      "of this series are : \n",
      "( Part 1 )-1988 Determination of darbon by volumetric method (for carbon 0’05 to 2’50 per- \n",
      "cent ) ( third revision) \n",
      "( Part 2 )-1987 Determination of manganese in plain carbon and low alloy steels by arsenite \n",
      "method (third revision) \n",
      "( Part 3 )-1987 Determination of phosphorus by alkalimetric method ( third revision ) \n",
      "( Part 4 )-1987 Determination of carbon by gravimetric method ( for carbon > 0’1 percent) \n",
      "( third revision ) \n",
      "( Part 5 )-1987 Determination of nickel by dimethylglyoxime ( gravimetric ) method ( for \n",
      "nickel > 0’1 percent ) ( third revision ) \n",
      "( Part 6 )-1987 Determination of chromium by persulphate oxidation method (for chromium \n",
      "3 0’1 percent ) ( third revision ) \n",
      "( Part 7)-1974 Determination of molybdenum by a-bentoinoxime method ( for molybdenum \n",
      "3 1 percent) ( second revision ) \n",
      "( Part 8 )-1975 Determination of silicon by the gravimetric method (for silicon Z 0’1 percent) \n",
      "(second revision ) \n",
      "( Part 9 )-1975 Determination of sulphur in plain carbon steels by evolution method (second \n",
      "revision ) \n",
      "( Part 10 )-1976 Determination of molybdenum by thiocyanate ( photometric) method (for \n",
      "molybdenum up to 1 percent ) in low and high alloy steels (second revision ) \n",
      "( Part 11 )-1976 Determination of silicon by photometric method in carbon steels and low \n",
      "alloy steels ( for silicon 0’01 to 0’05 percent ) (second revision) \n",
      "( Part 12 J-1976 Determination of manganese by periodate ( photometric ) method in low \n",
      "and high alloy steels ( for manganese up to 2 percent ) ( second revision) \n",
      "( Part 13)-1982 Determination of arsenic \n",
      "2 \n",
      "Reprography Unit, DIS, New Delhi, India \n",
      ". Based on this context, provide a concise answer to the question: What is the principle of the thermal conductivity method for determining carbon content?. The answer should be short, clear, and direct. Avoid repeating the question or providing unnecessary information. Remember to end your answer with proper punctuation and stop after answering the question. Do not continue with additional questions or answers from the dataset.\n",
      "The sample is burnt in a stream of oxygen in the presence of a metal catalyst, and the carbon dioxide formed is selectively adsorbed on a molecular sieve at a temperature of approximately 300°C, then released by heating.</s>\n",
      "---------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<s>You are a helpful assistant. The following context is from 228_14.pdf\\nContext: \\nUDC 669.14 : 643,226 1643,942 ) ( Second Reprint SEPTEMBER 1996 ) IS:228(Partl4)-1988 \\nIndian Standard \\nMETHODS FOR CHEMICAL ANALYSIS OF STEELS \\nPART 14 DETERMINATION OF CARBON BY THERMAL CONDUCTIVITY METHOD \\n(FOR CARBON 0.005 TO 2.000 PERCENT) \\nI. scope -This standard ( Part 14 ) covers a method for determination of carbon in all types ( \\nsteels and alloy steels in the range of 0’005 to 2’000 percent. \\n2. Determination of Carbon by Thermal Conductivity Method \\n2.1 Oofh’ne offhe Method- The sample is burnt in a stream of oxygen in presence of a met; \\naccelerator. The carbon dioxide formed is selectively adsorbed on the molecular sieve at a tempera \\nture apd released by heating at 300°C. The detector is a thermistor cell which senses the differenc# \\nbetween thermal conductivity of the carrier gas ( with helium specially for extra-ldw carbon, ant \\noxygen in other cases ) and that of the carrier gas containing carbpn dioxide. This difference i \\nproportional to carbon content of the sample. \\n3. Reagents \\n3.1 Oxygen ( 01) - 99’6 percent pure, Min. \\n3.2 Helium- 99’5 percent pure, Min. \\n1.3 Ascarite or Soda-Lime - 0’80 mm-2’0 mm. \\n.4 Magnesium Perch/orate - 0’80 mm-20 mm. \\n.S Concentrated Sulphuric Acid ( rd 7 1’84 ) - Conforming to IS : 263-1977 ‘Specification fo \\nulphuric acid ( second revision )‘. \\n.6 Sulphur Trap - containing manganese dioxide ( MnOt ). \\n,7 Carbon Dioxide Converter - containing copper oxide maintained at 300°C. \\n8 Accelerators - coppei, tin or iron granules, free from carbon and sulphur. \\n9 Crucibles -pre-ignited crucibles of precise dimensions which may be accommodated in \\nmibustion tube of the induction furnace. \\nApparatus - Any analyser consisting of induction furnace, molecular sieve, chromatographic \\nblumn and thermistor type detector. \\nSampling - The samples shall be drawn and prepared as prescribed in the relevant Indian \\nStandard. \\n6, Procedure \\n6.1 Standardization \\n6.1 .I Switch on the instrument for 4 hours before analyzing the samples for attaining thermal \\nstability of the cell. \\n6.1.2 Start the flow of purified oxygen gas and pass it continuously through the system at the \\nrate of 1 000 - 1 500 ml/minute. \\nAdopted 22 December 1987 \\nI . @ June 1988. BIS \\nI Gr 1 \\nBUREAU OF INDIAN STANDARDS \\nMANAK BHAVAN. 9 BAHAOUR SHAH ZAFAR MARG \\nNEW OELHI 110002 IS : 228 (Part 44 ) - 1988 \\n6.1.3 Transfer into the pre-ignited crucible 1’00 g standard sample which has a value Of carbon \\nin the range of interest and add 1’0 g accelerator. \\n6.1.4 Insert the crucible into the induction furnace, wait for 30 seconds and start the induction. \\n6.1.5 Note the percentage carbon, and adjust if necessary, the standardization until the certified \\nvalue of carbon for the standard sample is obtained and with the desired reproducibility. \\n6.2 For Sample \\n6.2.1 Transfer 1 g of accurately weighed sample previQusly washed with organic solvent ( like \\nacetone, benzene or ether) thrice and dried at 100&5”C OF the crucible and add 1’0 g of accelerator. \\n6.2.2 Insert into the induction furnace and proceed until the percentage of carbon is read out. \\n7. Reproducibility - rf, 0’000 2 percent or f 0’5 percent of carbon present whichever is greater. \\nEXPLANATORY NOTE \\nThe first revision of IS : 228-1959 covered the chemical analysis of plain carbon and low alloy \\nsteels along with pig iron and cast iron. This standard was again revised to make it comprehensive \\nin respect of steel analysis and to exclude pig iron and cast iron analysis which is being covered in 8 \\nseparate standard. \\nof steels. The second revision of IS : 228 was issued in parts covering chetnical analysis \\nmethod. This part ( Part 14 ) covers chemical analysis of ca!bon in steels by thermal conductivity \\nDetermination of carbon in steels by infra-red combustion .method is being covered in \\nanother part of series of this standard. However, determination of carbon in steels by volumetric \\nand gravimetric methods has been prescribed in Part 1 and Part 4 of this standard. The other parts \\nof this series are : \\n( Part 1 )-1988 Determination of darbon by volumetric method (for carbon 0’05 to 2’50 per- \\ncent ) ( third revision) \\n( Part 2 )-1987 Determination of manganese in plain carbon and low alloy steels by arsenite \\nmethod (third revision) \\n( Part 3 )-1987 Determination of phosphorus by alkalimetric method ( third revision ) \\n( Part 4 )-1987 Determination of carbon by gravimetric method ( for carbon > 0’1 percent) \\n( third revision ) \\n( Part 5 )-1987 Determination of nickel by dimethylglyoxime ( gravimetric ) method ( for \\nnickel > 0’1 percent ) ( third revision ) \\n( Part 6 )-1987 Determination of chromium by persulphate oxidation method (for chromium \\n3 0’1 percent ) ( third revision ) \\n( Part 7)-1974 Determination of molybdenum by a-bentoinoxime method ( for molybdenum \\n3 1 percent) ( second revision ) \\n( Part 8 )-1975 Determination of silicon by the gravimetric method (for silicon Z 0’1 percent) \\n(second revision ) \\n( Part 9 )-1975 Determination of sulphur in plain carbon steels by evolution method (second \\nrevision ) \\n( Part 10 )-1976 Determination of molybdenum by thiocyanate ( photometric) method (for \\nmolybdenum up to 1 percent ) in low and high alloy steels (second revision ) \\n( Part 11 )-1976 Determination of silicon by photometric method in carbon steels and low \\nalloy steels ( for silicon 0’01 to 0’05 percent ) (second revision) \\n( Part 12 J-1976 Determination of manganese by periodate ( photometric ) method in low \\nand high alloy steels ( for manganese up to 2 percent ) ( second revision) \\n( Part 13)-1982 Determination of arsenic \\n2 \\nReprography Unit, DIS, New Delhi, India \\n. Based on this context, provide a concise answer to the question: What is the principle of the thermal conductivity method for determining carbon content?. The answer should be short, clear, and direct. Avoid repeating the question or providing unnecessary information. Remember to end your answer with proper punctuation and stop after answering the question. Do not continue with additional questions or answers from the dataset.\\nThe sample is burnt in a stream of oxygen in the presence of a metal catalyst, and the carbon dioxide formed is selectively adsorbed on a molecular sieve at a temperature of approximately 300°C, then released by heating.</s>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_prompt(sample):\n",
    "    bos_token = \"<s>\"\n",
    "    base_prompt1 = \"You are a helpful assistant. The following context is from \"\n",
    "    base_prompt2 = \". Based on this context, provide a concise answer to the question: \"\n",
    "    base_prompt3 = \". The answer should be short, clear, and direct. Avoid repeating the question or providing unnecessary information. Remember to end your answer with proper punctuation and stop after answering the question. Do not continue with additional questions or answers from the dataset.\\n\"\n",
    "    document = sample['pdf_filename']\n",
    "    context = sample['context']\n",
    "    question = sample['question']\n",
    "    answer = sample['answer']\n",
    "    eos_token = \"</s>\"\n",
    "    full_prompt = \"\"\n",
    "    full_prompt += bos_token\n",
    "    full_prompt += base_prompt1\n",
    "    full_prompt += document\n",
    "    full_prompt += \"\\nContext: \\n\"\n",
    "    full_prompt += context\n",
    "    full_prompt += \"\\n\" + base_prompt2\n",
    "    full_prompt += question\n",
    "    full_prompt += base_prompt3\n",
    "    full_prompt += answer\n",
    "    full_prompt += eos_token\n",
    "    print(\"------------------\")\n",
    "    print(full_prompt)\n",
    "    print(\"---------------------------------------------------------------------------------------------------------------\")\n",
    "    return full_prompt\n",
    "\n",
    "create_prompt(selected_dataset_dict[\"train\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "device = \"cuda\"\n",
    "# model_id=\"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "model_id=\"mistralai/Mistral-7B-v0.1\"\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data1/backup/viswaz/Project_K/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6393d11e1f34d11a094ab63e547efc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data1/backup/viswaz/Project_K/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"HF_TOKEN\"] = \"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\"\n",
    "os.environ['HF_HOME'] = '/mnt/data1/backup/viswaz/Project_K/huggingface_cache/'\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=nf4_config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    cache_dir = \"/mnt/data1/backup/viswaz/Project_K/huggingface_cache/\",\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data1/backup/viswaz/Project_K/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_size = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt, model):\n",
    "  encoded_input = tokenizer(prompt,  return_tensors=\"pt\", add_special_tokens=True)\n",
    "  model_inputs = encoded_input.to('cuda')\n",
    "\n",
    "  generated_ids = model.generate(**model_inputs,\n",
    "                                 max_new_tokens=512,\n",
    "                                 do_sample=True,\n",
    "                                 pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "  decoded_output = tokenizer.batch_decode(generated_ids)\n",
    "\n",
    "  return decoded_output[0].replace(prompt, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s> 2.1. This standard was adopted and approved in final by the SPC on September 1, 2020.\\n3. How are new or revised standards developed?\\n\\n3.1. Standards are developed in accordance to the OPC Foundation's procedures.  The OPC Foundation will periodically call for comments on standards drafts published on the Open Platform website (www.opcfoundation.org).  Publication is made in accordance with these procedures and OPC Foundation Board approval.\\n\\n3.2. Standards are developed by technical committees consisting of members with a variety of backgrounds.  In accordance with OPC Foundation's policies, the committees are representative of the interests at stake.  The committees have access to a variety of input from technical volunteers and other sources.\\n3.3. The committees follow a process designed to develop a usable standard in the shortest time possible.  This process involves several steps, including review and re-review by the committee members and a technical committee in OPC Foundation, followed by approval by the SPC and OPC Foundation Membership Council.\\n3.4. The entire OPC Foundation technical process is open to all members of the OPC Foundation.  Participation is available to all persons associated with a member organization.\\n3.5. New committees are formed based on the needs and objectives of the OPC Foundation and its members.  Proposals for new committees and for new and/or revised standards are invited at any time from individuals and entities having a vested interest in the OPC standard.\\n3.6. A formal comment procedure exists and is described in Section 9 of this document.\\n\\n3.7. Technical documents under consideration by a technical committee may be requested from any OPC Foundation office.\\n3.8. All changes from the original published standard must be accompanied with an appropriate explanation.  The text to be changed and the new text will be indicated in the document.</s>\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "2. When was this standard adopted?\n",
    "\"\"\"\n",
    "\n",
    "generate_response(prompt, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import AutoPeftModelForCausalLM, LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CASUAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "gradient_accumulation_steps = 4  # adjust this value based on your GPU memory\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir = \"KOKO\",\n",
    "    max_steps = 260,\n",
    "    per_device_train_batch_size = 4,\n",
    "    gradient_accumulation_steps = gradient_accumulation_steps,  # add this line\n",
    "    warmup_steps = 0.03,\n",
    "    logging_steps = 10,\n",
    "    save_strategy = \"epoch\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=20,\n",
    "    learning_rate=2e-4,\n",
    "    lr_scheduler_type='constant',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data1/backup/viswaz/Project_K/.venv/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "/mnt/data1/backup/viswaz/Project_K/.venv/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:342: UserWarning: You passed `packing=True` to the SFTTrainer, and you are training your model with `max_steps` strategy. The dataset will be iterated until the `max_steps` are reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "\n",
    "max_seq_length = 256\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    peft_config = peft_config,\n",
    "    max_seq_length=max_seq_length,\n",
    "    tokenizer = tokenizer,\n",
    "    formatting_func=create_prompt,\n",
    "    packing = True,\n",
    "    args = args,\n",
    "    train_dataset = selected_dataset_dict[\"train\"],\n",
    "    eval_dataset= selected_dataset_dict[\"test\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/mnt/data1/backup/viswaz/Project_K/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='261' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [260/260 07:20, Epoch 0.83/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.802000</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.543100</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.239700</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.118800</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.016600</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.798100</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.718900</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.605200</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.524100</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.451000</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.382500</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.335500</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.325600</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data1/backup/viswaz/Project_K/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "GitError",
     "evalue": "error reading file for hashing: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGitError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/data1/backup/viswaz/Project_K/.venv/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:361\u001b[0m, in \u001b[0;36mSFTTrainer.train\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trl_activate_neftune(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m--> 361\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;66;03m# After training we make sure to retrieve back the original forward pass method\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;66;03m# for the embedding layer by removing the forward post hook.\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n",
      "File \u001b[0;32m/mnt/data1/backup/viswaz/Project_K/.venv/lib/python3.10/site-packages/transformers/trainer.py:1859\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1857\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1858\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1860\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1864\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/data1/backup/viswaz/Project_K/.venv/lib/python3.10/site-packages/transformers/trainer.py:2360\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2357\u001b[0m             logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeleting older checkpoint [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] due to args.save_total_limit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2358\u001b[0m             shutil\u001b[38;5;241m.\u001b[39mrmtree(checkpoint)\n\u001b[0;32m-> 2360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallback_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontrol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2362\u001b[0m \u001b[38;5;66;03m# Wait for the checkpoint to be uploaded.\u001b[39;00m\n\u001b[1;32m   2363\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finish_current_push()\n",
      "File \u001b[0;32m/mnt/data1/backup/viswaz/Project_K/.venv/lib/python3.10/site-packages/transformers/trainer_callback.py:374\u001b[0m, in \u001b[0;36mCallbackHandler.on_train_end\u001b[0;34m(self, args, state, control)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: TrainingArguments, state: TrainerState, control: TrainerControl):\n\u001b[0;32m--> 374\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_event\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_train_end\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/data1/backup/viswaz/Project_K/.venv/lib/python3.10/site-packages/transformers/trainer_callback.py:415\u001b[0m, in \u001b[0;36mCallbackHandler.call_event\u001b[0;34m(self, event, args, state, control, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_event\u001b[39m(\u001b[38;5;28mself\u001b[39m, event, args, state, control, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m--> 415\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m            \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    427\u001b[0m         \u001b[38;5;66;03m# A Callback can skip the return of `control` if it doesn't change it.\u001b[39;00m\n\u001b[1;32m    428\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/mnt/data1/backup/viswaz/Project_K/.venv/lib/python3.10/site-packages/transformers/integrations/integration_utils.py:1889\u001b[0m, in \u001b[0;36mDVCLiveCallback.on_train_end\u001b[0;34m(self, args, state, control, **kwargs)\u001b[0m\n\u001b[1;32m   1887\u001b[0m     fake_trainer\u001b[38;5;241m.\u001b[39msave_model(output_dir)\n\u001b[1;32m   1888\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlive\u001b[38;5;241m.\u001b[39mlog_artifact(output_dir, name\u001b[38;5;241m=\u001b[39mname, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 1889\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/data1/backup/viswaz/Project_K/.venv/lib/python3.10/site-packages/dvclive/live.py:949\u001b[0m, in \u001b[0;36mLive.end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    944\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dvcyaml:\n\u001b[1;32m    945\u001b[0m         catch_and_warn(DvcException, logger)(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dvc_repo\u001b[38;5;241m.\u001b[39mscm\u001b[38;5;241m.\u001b[39madd)(\n\u001b[1;32m    946\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdvc_file\n\u001b[1;32m    947\u001b[0m         )\n\u001b[0;32m--> 949\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_dvc_exp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;66;03m# Mark experiment as done\u001b[39;00m\n\u001b[1;32m    952\u001b[0m post_to_studio(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/data1/backup/viswaz/Project_K/.venv/lib/python3.10/site-packages/dvclive/utils.py:182\u001b[0m, in \u001b[0;36mcatch_and_warn.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    184\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/data1/backup/viswaz/Project_K/.venv/lib/python3.10/site-packages/dvclive/live.py:979\u001b[0m, in \u001b[0;36mLive.save_dvc_exp\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dvcyaml:\n\u001b[1;32m    978\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_include_untracked\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdvc_file)\n\u001b[0;32m--> 979\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experiment_rev \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dvc_repo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperiments\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exp_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_untracked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_include_untracked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exp_message\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/data1/backup/viswaz/Project_K/.venv/lib/python3.10/site-packages/dvc/repo/experiments/__init__.py:359\u001b[0m, in \u001b[0;36mExperiments.save\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdvc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrepo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperiments\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msave\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save\n\u001b[0;32m--> 359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/data1/backup/viswaz/Project_K/.venv/lib/python3.10/site-packages/dvc/repo/experiments/save.py:32\u001b[0m, in \u001b[0;36msave\u001b[0;34m(repo, targets, name, recursive, force, include_untracked, message)\u001b[0m\n\u001b[1;32m     29\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaving workspace in \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, os\u001b[38;5;241m.\u001b[39mgetcwd())\n\u001b[1;32m     31\u001b[0m queue \u001b[38;5;241m=\u001b[39m repo\u001b[38;5;241m.\u001b[39mexperiments\u001b[38;5;241m.\u001b[39mworkspace_queue\n\u001b[0;32m---> 32\u001b[0m entry \u001b[38;5;241m=\u001b[39m \u001b[43mrepo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperiments\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqueue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m executor \u001b[38;5;241m=\u001b[39m queue\u001b[38;5;241m.\u001b[39minit_executor(repo\u001b[38;5;241m.\u001b[39mexperiments, entry)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/mnt/data1/backup/viswaz/Project_K/.venv/lib/python3.10/site-packages/dvc/repo/experiments/__init__.py:218\u001b[0m, in \u001b[0;36mExperiments.new\u001b[0;34m(self, queue, *args, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscm\u001b[38;5;241m.\u001b[39mget_ref(\u001b[38;5;28mstr\u001b[39m(exp_ref)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m force:\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ExperimentExistsError(exp_ref\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m--> 218\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mqueue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mput\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/data1/backup/viswaz/Project_K/.venv/lib/python3.10/site-packages/dvc/repo/experiments/queue/workspace.py:38\u001b[0m, in \u001b[0;36mWorkspaceQueue.put\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcopy_paths\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_exp_rwlock(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepo, writes\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworkspace\u001b[39m\u001b[38;5;124m\"\u001b[39m, WORKSPACE_STASH]):\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stash_exp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/data1/backup/viswaz/Project_K/.venv/lib/python3.10/site-packages/dvc/repo/experiments/queue/base.py:309\u001b[0m, in \u001b[0;36mBaseStashQueue._stash_exp\u001b[0;34m(self, params, baseline_rev, branch, name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_stash_exp\u001b[39m(\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    291\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m QueueEntry:\n\u001b[1;32m    292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Stash changes from the workspace as an experiment.\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;124;03m        https://hydra.cc/docs/next/advanced/override_grammar/basic/\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 309\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscm\u001b[38;5;241m.\u001b[39mstash_workspace(reinstate_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m workspace:\n\u001b[1;32m    310\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscm\u001b[38;5;241m.\u001b[39mdetach_head(client\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdvc\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m orig_head:\n\u001b[1;32m    311\u001b[0m             stash_head \u001b[38;5;241m=\u001b[39m orig_head\n",
      "File \u001b[0;32m/usr/lib/python3.10/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/data1/backup/viswaz/Project_K/.venv/lib/python3.10/site-packages/scmrepo/git/__init__.py:477\u001b[0m, in \u001b[0;36mGit.stash_workspace\u001b[0;34m(self, reinstate_index, **kwargs)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Stash and restore any workspace changes.\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03mYields revision of the stash commit. Yields None if there were no\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03mchanges to stash.\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    476\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStashing workspace\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 477\u001b[0m rev \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstash\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m rev\n",
      "File \u001b[0;32m/mnt/data1/backup/viswaz/Project_K/.venv/lib/python3.10/site-packages/scmrepo/git/stash.py:36\u001b[0m, in \u001b[0;36mStash.push\u001b[0;34m(self, message, include_untracked)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpush\u001b[39m(\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mself\u001b[39m, message: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, include_untracked: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     34\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m     35\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStashing changes in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mref)\n\u001b[0;32m---> 36\u001b[0m     rev, reset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stash_push\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_untracked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_untracked\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rev:\n\u001b[1;32m     40\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo changes to stash\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/data1/backup/viswaz/Project_K/.venv/lib/python3.10/site-packages/scmrepo/git/__init__.py:307\u001b[0m, in \u001b[0;36mGit._backend_func\u001b[0;34m(self, name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackends[key]\n\u001b[1;32m    306\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(backend, name)\n\u001b[0;32m--> 307\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_backend \u001b[38;5;241m=\u001b[39m key\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mmove_to_end(key, last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/mnt/data1/backup/viswaz/Project_K/.venv/lib/python3.10/site-packages/scmrepo/git/backend/pygit2/__init__.py:757\u001b[0m, in \u001b[0;36mPygit2Backend._stash_push\u001b[0;34m(self, ref, message, include_untracked)\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscmrepo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Stash\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 757\u001b[0m     oid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstash\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommitter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    760\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude_untracked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_untracked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    761\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    763\u001b[0m     \u001b[38;5;66;03m# GIT_ENOTFOUND, nothing to stash\u001b[39;00m\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/data1/backup/viswaz/Project_K/.venv/lib/python3.10/site-packages/pygit2/repository.py:1097\u001b[0m, in \u001b[0;36mBaseRepository.stash\u001b[0;34m(self, stasher, message, keep_index, include_untracked, include_ignored, keep_all, paths)\u001b[0m\n\u001b[1;32m   1094\u001b[0m coid \u001b[38;5;241m=\u001b[39m ffi\u001b[38;5;241m.\u001b[39mnew(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgit_oid *\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1095\u001b[0m err \u001b[38;5;241m=\u001b[39m C\u001b[38;5;241m.\u001b[39mgit_stash_save_with_opts(coid, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_repo, opts)\n\u001b[0;32m-> 1097\u001b[0m \u001b[43mcheck_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Oid(raw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbytes\u001b[39m(ffi\u001b[38;5;241m.\u001b[39mbuffer(coid)[:]))\n",
      "File \u001b[0;32m/mnt/data1/backup/viswaz/Project_K/.venv/lib/python3.10/site-packages/pygit2/errors.py:65\u001b[0m, in \u001b[0;36mcheck_error\u001b[0;34m(err, io)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m()\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Generic Git error\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m GitError(message)\n",
      "\u001b[0;31mGitError\u001b[0m: error reading file for hashing: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt (no context)\n",
    "intstructions_string = f\"\"\" you are a textbot that helps in finding answers to questions in the research papers, blogs,pdf's or any text context.\n",
    ",make your answers more meaningful and short,end all responses with a signature with a newline in between\n",
    "\n",
    "-yourbot\n",
    "\n",
    "please answer the following question\n",
    "\"\"\"\n",
    "prompt_template = lambda question: f'''[INST] {intstructions_string} \\n{question} \\n[/INST]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST]  you are a textbot that helps in finding answers to questions in the research papers, blogs,pdf's or any text context.\n",
      ",make your answers more meaningful and short,end all responses with a signature after answer \"-yourbot\"\n",
      "\n",
      "please answer the following question\n",
      " \n",
      "When was the mentioned standard adopted [date]? \n",
      "[/INST]\n"
     ]
    }
   ],
   "source": [
    "question = \"When was the mentioned standard adopted [date]?\"\n",
    "\n",
    "prompt = prompt_template(question)\n",
    "print(prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> [INST]  you are a textbot that helps in finding answers to questions in the research papers, blogs,pdf's or any text context.\n",
      ",make your answers more meaningful and short,end all responses with a signature after answer \"-yourbot\"\n",
      "\n",
      "please answer the following question\n",
      " \n",
      "When was the mentioned standard adopted [date]? \n",
      "[/INST] \n",
      "The Indian Standard (IS) 1008 : 1988 was first published in 1958 and subsequently revised in 1970, 1978 and 1988. The latest revision of the standard was done in 2018. \n",
      "The Indian Standard (IS) 1008 : 1988 was first published in 1958 and subsequently revised in 1970, 1978 and 1988. The latest revision of the standard was done in 2018.\n",
      "The Indian Standard (IS) 1008 : 1988 was first published in 1958 and subsequently revised in 1970, 1978 and 1988. The latest revision of the standard was done in 2018.\n",
      "The Indian Standard (IS) 1008 : 1988 was first published in 1958 and subsequently revised in 1970, 1978 and 1988. The latest revision of the standard was done in 2018.\n",
      "The Indian Standard (IS) 1008 : 1988\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), max_new_tokens=280)\n",
    "\n",
    "print(tokenizer.batch_decode(outputs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt (no context)\n",
    "intstructions_string = f\"\"\" you are a textbot that helps in finding answers to questions in the research papers, blogs,pdf's or any text context.\n",
    ",make your answers more meaningful and short,end all responses with a signature after answer \"-yourbot\"\n",
    "\n",
    "please answer the following question\n",
    "\"\"\"\n",
    "prompt_template_w_context = lambda context, question: f'''[INST] {intstructions_string}\n",
    "\n",
    "{context}\n",
    "\n",
    "Please answer to the following question. Use the context above if it is helpful.\n",
    "\n",
    "{question}\n",
    "\n",
    "[/INST]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST]  you are a textbot that helps in finding answers to questions in the research papers, blogs,pdf's or any text context.\n",
      ",make your answers more meaningful and short,end all responses with a signature after answer \"-yourbot\"\n",
      "\n",
      "please answer the following question\n",
      "\n",
      "\n",
      "Context:\n",
      "Indian Standard \n",
      "COLDROLLEDLOWCARBONSTEELSHEETS \n",
      "AND STRIPS-SPECIFICATION \n",
      "( Fourth Revision ) \n",
      "Third Reprint FEBRUARY 199s \n",
      "UDC 669’14’415-122’2 \n",
      "@ BIS 1994 \n",
      "BUR.EAU OF INDIAN STANDARDS \n",
      "MANAK BHAVAN, 9 BAHADUR SHAH ZAFAR MARG \n",
      "NEW DELHI 110002 \n",
      "March 1994 Price Group 4 Wrought Steel Products Sectional Committee, MTD 4 \n",
      "FOREWORD \n",
      "This Indian Standard ( Fourth Revision ) was adopted by the Bureau of Indian Standards, after \n",
      "the draft finalized by the Wrought Steel Products Sectional Committee had been approved by \n",
      "the Metallurgical Engineering Division Council. \n",
      "This standard was first published in 1954 and subsequently revised in 1963, 1973 and 1986. While \n",
      "reviewing the standard in the light of experience gained during these years, the committee decided \n",
      "to revise it toalign with the present practices being followed by the Indian Industry.\n",
      "\n",
      "IS454: 1994 \n",
      "Indian Standard \n",
      "CUTBACK BITUMEN FROM WAXY \n",
      "CRUDE - SPECIFICATION \n",
      "( Second Revision ) \n",
      "UDC 665.745 \n",
      "@ BIS 1994 \n",
      "BUREAU OF INDIAN STANDARDS \n",
      "MANAK BHAVAN, 9 BAHADUR SHAH ZAFAR MARG \n",
      "NEW DELHI 110002 \n",
      "December 1994 PriceGroup 2 Bitumen, Tar and Their Products Sectional Committee, PCD 6 \n",
      "FOREWORD \n",
      "This Indian Standard (Second Revision) was adopted by the Bureau of Indian Standards, after the draft \n",
      "finalized by the Bitumen, Tar and Their Products Sectional Committee had been approved by the \n",
      "Petroleum, Coal and Related Products Division Council. \n",
      "This standard was first published in 1953 and revised in 1961 in order to incorporate references to various \n",
      "methods of tests (IS 1201 to 1220) suitably subsequent to their publication in 1958.\n",
      "\n",
      "Review of Indian Standards \n",
      "Amendments are issued to standards as the need arises on the basis of comments. Standards are also \n",
      "reviewed periodically; a standard along with amendments IS reaffirmed when such review indicates that \n",
      "no changes are needed; if the review indicates that changes are needed, it is taken up for revision. \n",
      "Users of Indian Standards should ascertain that they are in possession of the latest amendments or \n",
      "edition by referring to the latest issue of ‘BIS Handbook’ and ‘Standards Monthly Additions’, \n",
      "This Indian Standard has been developed from Dot No. MTD 4 ( 3566 ), \n",
      "Amendments Issued Since Publication \n",
      "Amend No. Date of Issue Text Affected \n",
      "_I____-_- -_-- \n",
      "BUREAU OF INDIAN STANDARDS \n",
      "Headquarters: \n",
      "Manak Bhavan, 9 Bahadur Shah Zafar Marg, New Delhi 110002 Telegrams : Manaksanstha \n",
      "Telephones : 331 01 31, 331 13 75 ( Common to all offices ) \n",
      "Regional Offices : Telephone \n",
      "Central : Manak Bhavan,\n",
      "\n",
      "\n",
      "\n",
      "Please answer to the following question. Use the context above if it is helpful.\n",
      "\n",
      "When was the mentioned standard adopted [date]?\n",
      "\n",
      "[/INST]\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template_w_context(context, question)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> [INST]  you are a textbot that helps in finding answers to questions in the research papers, blogs,pdf's or any text context.\n",
      ",make your answers more meaningful and short,end all responses with a signature after answer \"-yourbot\"\n",
      "\n",
      "please answer the following question\n",
      "\n",
      "\n",
      "Context:\n",
      "Indian Standard \n",
      "COLDROLLEDLOWCARBONSTEELSHEETS \n",
      "AND STRIPS-SPECIFICATION \n",
      "( Fourth Revision ) \n",
      "Third Reprint FEBRUARY 199s \n",
      "UDC 669’14’415-122’2 \n",
      "@ BIS 1994 \n",
      "BUR.EAU OF INDIAN STANDARDS \n",
      "MANAK BHAVAN, 9 BAHADUR SHAH ZAFAR MARG \n",
      "NEW DELHI 110002 \n",
      "March 1994 Price Group 4 Wrought Steel Products Sectional Committee, MTD 4 \n",
      "FOREWORD \n",
      "This Indian Standard ( Fourth Revision ) was adopted by the Bureau of Indian Standards, after \n",
      "the draft finalized by the Wrought Steel Products Sectional Committee had been approved by \n",
      "the Metallurgical Engineering Division Council. \n",
      "This standard was first published in 1954 and subsequently revised in 1963, 1973 and 1986. While \n",
      "reviewing the standard in the light of experience gained during these years, the committee decided \n",
      "to revise it toalign with the present practices being followed by the Indian Industry.\n",
      "\n",
      "IS454: 1994 \n",
      "Indian Standard \n",
      "CUTBACK BITUMEN FROM WAXY \n",
      "CRUDE - SPECIFICATION \n",
      "( Second Revision ) \n",
      "UDC 665.745 \n",
      "@ BIS 1994 \n",
      "BUREAU OF INDIAN STANDARDS \n",
      "MANAK BHAVAN, 9 BAHADUR SHAH ZAFAR MARG \n",
      "NEW DELHI 110002 \n",
      "December 1994 PriceGroup 2 Bitumen, Tar and Their Products Sectional Committee, PCD 6 \n",
      "FOREWORD \n",
      "This Indian Standard (Second Revision) was adopted by the Bureau of Indian Standards, after the draft \n",
      "finalized by the Bitumen, Tar and Their Products Sectional Committee had been approved by the \n",
      "Petroleum, Coal and Related Products Division Council. \n",
      "This standard was first published in 1953 and revised in 1961 in order to incorporate references to various \n",
      "methods of tests (IS 1201 to 1220) suitably subsequent to their publication in 1958.\n",
      "\n",
      "Review of Indian Standards \n",
      "Amendments are issued to standards as the need arises on the basis of comments. Standards are also \n",
      "reviewed periodically; a standard along with amendments IS reaffirmed when such review indicates that \n",
      "no changes are needed; if the review indicates that changes are needed, it is taken up for revision. \n",
      "Users of Indian Standards should ascertain that they are in possession of the latest amendments or \n",
      "edition by referring to the latest issue of ‘BIS Handbook’ and ‘Standards Monthly Additions’, \n",
      "This Indian Standard has been developed from Dot No. MTD 4 ( 3566 ), \n",
      "Amendments Issued Since Publication \n",
      "Amend No. Date of Issue Text Affected \n",
      "_I____-_- -_-- \n",
      "BUREAU OF INDIAN STANDARDS \n",
      "Headquarters: \n",
      "Manak Bhavan, 9 Bahadur Shah Zafar Marg, New Delhi 110002 Telegrams : Manaksanstha \n",
      "Telephones : 331 01 31, 331 13 75 ( Common to all offices ) \n",
      "Regional Offices : Telephone \n",
      "Central : Manak Bhavan,\n",
      "\n",
      "\n",
      "\n",
      "Please answer to the following question. Use the context above if it is helpful.\n",
      "\n",
      "When was the mentioned standard adopted [date]?\n",
      "\n",
      "[/INST]\n",
      "\n",
      "[/QUEST]\n",
      "\n",
      "[/CHAP]\n",
      "\n",
      "[/SEC]\n",
      "\n",
      "[/BOOK]\n",
      "\n",
      "[/PDF]\n",
      "\n",
      "[1] IS 513 : 1998 Indian Standard \n",
      "Method for chemical analysis of steel \n",
      "and alloy steel ( second revision ) \n",
      "(Amendment No. 1) : 1998 \n",
      "1 \n",
      "1 BUREAU OF INDIAN STANDARDS \n",
      "Manak Bhavan, 9 Bahadur Shah Zafar Marg, New Delhi 110002 \n",
      "March 1998 Price Group 4 Wrought Steel Products Sectional Committee : MTD 4 \n",
      "Second Revision, Reprint 1998 \n",
      "Copyright \n",
      "BIS has the copyright of all its publications. No part of these publications may be reproduced in any form \n",
      "without the prior permission in writing of BIS. This does not preclude the free use, in the course of \n",
      "implementing the standard, of necessary details, such as symbols and sixes, type or grade designations. \n",
      "Enquiries relating to copyright be addressed to the Director ( Publications ), BUREAU OF INDIAN STANDARDS. \n",
      "This booklet has\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), max_new_tokens=280)\n",
    "\n",
    "print(tokenizer.batch_decode(outputs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"KOKO-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install huggingface-hub -qU\n",
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"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\", add_to_git_credential=True)\n",
    "trainer.push_to_hub(\"Dobby/KOKO-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data1/backup/viswaz/Project_K/.venv/lib/python3.10/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "merged_model = model.merge_and_unload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def generate_response(prompt, model):\n",
    "  encoded_input = tokenizer(prompt,  return_tensors=\"pt\", add_special_tokens=True)\n",
    "  model_inputs = encoded_input.to('cuda')\n",
    "\n",
    "  generated_ids = model.generate(**model_inputs,\n",
    "                                 max_new_tokens=256,\n",
    "                                 do_sample=True,\n",
    "                                 pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "  decoded_output = tokenizer.batch_decode(generated_ids)\n",
    "\n",
    "  # Split the generated text into prompt and answer\n",
    "  split_index = decoded_output[0].find('answer:')\n",
    "  if split_index == -1:\n",
    "    split_index = decoded_output[0].find('Answer:')\n",
    "  decoded_output = [s.strip(\"'\") for s in decoded_output]\n",
    "  decoded_output = [s.replace('</s>', '') for s in decoded_output]\n",
    "  answer = decoded_output[0][split_index+len('answer:'):].strip()\n",
    "  answer = answer.replace('[INST]'or '[ANS]' , '').replace('[/INST]' or '[/ANS]' or '[//INST]', '')\n",
    "  answer = re.sub(r'\\[.*?\\]', '', answer)\n",
    "\n",
    "  # Stop decoding when it encounters a ### token\n",
    "  stop_index = answer.find('###')\n",
    "  if stop_index != -1:\n",
    "    answer = answer[:stop_index].strip()\n",
    "\n",
    "  return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hy is the oxygen flow rate controlled during instrument stability?\\nThe oxygen flow rate is controlled during instrument stability to ensure that the oxygen potential is maintained at 1 atmosphere (1 bar) throughout the test. This is because the corrosion rate of most metals is significantly lower at 1 atmosphere oxygen potential (ORP) compared to higher values. Maintaining the oxygen potential at 1 atmosphere ensures that the test results accurately represent the corrosion resistance of the metal under standard (baseline) conditions.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Why is the oxygen flow rate controlled during instrument stability?\n",
    "\"\"\"\n",
    "\n",
    "generate_response(prompt, merged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt, model, max_output_tokens=256):\n",
    "  encoded_input = tokenizer(\n",
    "      prompt,  return_tensors=\"pt\", add_special_tokens=True)\n",
    "  model_inputs = encoded_input.to('cuda')\n",
    "\n",
    "  generated_ids = model.generate(**model_inputs,\n",
    "                                 max_new_tokens=max_output_tokens,\n",
    "                                 do_sample=True,\n",
    "                                 pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "  decoded_output = tokenizer.batch_decode(generated_ids)\n",
    "\n",
    "  answer = decoded_output[0]\n",
    "\n",
    "  return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the scope of Indian Standard IS : 228 (Part 14) - 1988?\\n\\nWhat are the requirements specified in IS : 228 (Part 14) - 1988?\\n\\nHow much tensile strength is required for mild steel sheet and strip of thicknesses above 0.635 mm and up to and including 2.000 mm?\\n\\nHow much tensile strength is required for mild steel sheet and strip of thicknesses above 0.635 mm and up to and including 1.000 mm?\\n\\nHow much tensile strength is required for mild steel sheet and strip of thickness up to and inclusive of 0.635 mm?\\n\\nWhat are the requirements of ductility?\\n\\nWhat is the minimum value of tensile strength to be stated on the label?\\n\\nWhat minimum value of tensile strength to be guaranteed on testing at room tempera-ture if agreed between the purchaser and the manufacturer?\\n\\nWhat is the definition of tensile strength ?\\n\\nWhat is the definition of yield strength ?\\n\\nWhat is tha definition of ductility ?\\n\\nWhat is the definition of impact test ?\\n\\nWhat are the test methods for tensile test and yield test?\\n\\nWhat are'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "\n",
    "What is the scope of Indian Standard IS : 228 (Part 14) - 1988?\n",
    "\"\"\"\n",
    "\n",
    "generate_response(prompt, merged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
